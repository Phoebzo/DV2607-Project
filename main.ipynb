{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DV2607 Project Notebook\n",
    "### Authors:\n",
    "### Oliver Ljung (ollj19@student.bth.se)\n",
    "### Phoebe Waters (phaa19@student.bth.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phoebe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Flatten, Dense, Input, Activation, BatchNormalization, LeakyReLU, Reshape, UpSampling2D, Dropout, ReLU\n",
    "from keras import Sequential, Model\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as KB\n",
    "\n",
    "from keras.losses import BinaryCrossentropy, CategoricalCrossentropy, Hinge, SquaredHinge, MeanSquaredError, Loss\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import art\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions\n",
    "\n",
    "def create_classifier():\n",
    "    # Create a CNN model\n",
    "    # Add input\n",
    "    input = Input(shape = (28,28,1))\n",
    "\n",
    "    model = Sequential(name=\"mnist_classifier\")\n",
    "\n",
    "    # Add Convolution layers\n",
    "    model.add(Conv2D(28, (3,3), activation='relu', input_shape=(28,28,1), name=\"image_input\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(56, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(56, (3,3), activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add predictive layers\n",
    "    model.add(Dense(56, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax', name=\"classication_output\"))\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # Get ouput from model\n",
    "    prediction = model(input)\n",
    "\n",
    "    # return model\n",
    "    return Model(input, prediction, name=\"mnist_classifier\")\n",
    "\n",
    "def create_generator():\n",
    "    # Create a CNN model\n",
    "    model = Sequential(name=\"generator\")\n",
    "\n",
    "    model.add(Dense(7*7*28, activation='relu', input_dim=100, name=\"noise_input\"))\n",
    "    model.add(Reshape((7,7,28)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(28, (3,3), activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(56, (3,3), activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2D(1, (3,3), activation='relu', padding=\"same\"))\n",
    "    model.add(Activation('tanh', name=\"image_output\"))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    input = Input(shape = (100))\n",
    "    \n",
    "    img = model(input)\n",
    "    \n",
    "    # return model\n",
    "    return Model(input, img, name=\"generator\")\n",
    "\n",
    "def create_adv_generator():\n",
    "    # Create a CNN model\n",
    "\n",
    "    # Enocder\n",
    "    encoder = Sequential(name=\"adv_generator_encoder\")\n",
    "    encoder.add(Conv2D(32, (3,3), activation='relu', padding=\"same\", input_shape=(28,28,1), name=\"image_input\"))\n",
    "    encoder.add(BatchNormalization(momentum=0.8))\n",
    "    encoder.add(UpSampling2D())\n",
    "    \n",
    "    encoder.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    encoder.add(BatchNormalization(momentum=0.8))\n",
    "    encoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Bottle neck w residual block\n",
    "    resblock = Sequential(name=\"resblock\")\n",
    "    resblock.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    resblock.add(BatchNormalization(momentum=0.8))\n",
    "    resblock.add(ReLU())\n",
    "\n",
    "    resblock.add(Dropout(0.25))\n",
    "\n",
    "    resblock.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    resblock.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    resblock.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    resblock.add(BatchNormalization(momentum=0.8))\n",
    "    resblock.add(ReLU())\n",
    "\n",
    "    resblock.add(Dropout(0.25))\n",
    "\n",
    "    resblock.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    resblock.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    resblock.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    resblock.add(BatchNormalization(momentum=0.8))\n",
    "    resblock.add(ReLU())\n",
    "\n",
    "    resblock.add(Dropout(0.25))\n",
    "\n",
    "    resblock.add(Conv2D(124, (3,3), padding=\"same\"))\n",
    "    resblock.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    # Decoder\n",
    "    decoder = Sequential(name=\"adv_generator_decoder\")\n",
    "    decoder.add(Conv2DTranspose(32, (3,3), activation='relu', padding=\"same\"))\n",
    "    decoder.add(BatchNormalization(momentum=0.8))\n",
    "    decoder.add(UpSampling2D())\n",
    "\n",
    "    decoder.add(Conv2DTranspose(64, (3,3), padding=\"same\"))\n",
    "    decoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    decoder.add(MaxPooling2D((4, 4)))\n",
    "    decoder.add(Conv2DTranspose(1, (3,3), padding=\"same\"))\n",
    "    decoder.add(Activation('tanh', name=\"adv_image_output\"))\n",
    "    \n",
    "    # Combining layers to model\n",
    "    input = Input(shape = (28,28,1))\n",
    "    encoding = encoder(input)\n",
    "    bottleneck = resblock(encoding) + encoding\n",
    "    bottleneck = resblock(bottleneck) + bottleneck\n",
    "    bottleneck = resblock(bottleneck) + bottleneck\n",
    "    perturbations = decoder(bottleneck)\n",
    "    \n",
    "    model = Model(input, perturbations, name=\"adv_generator\")\n",
    "    print(model.summary())\n",
    "    \n",
    "    # return model\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_discriminator():\n",
    "    # Create a CNN model\n",
    "    model = Sequential(name=\"discriminator\")\n",
    "\n",
    "    # Add Convolution layers\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28,28,1), name=\"image_input\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(124, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Add predictive layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid', name=\"validity_output\"))\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # Add input\n",
    "    input = Input(shape = (28,28,1))\n",
    "\n",
    "    # Get ouput from model\n",
    "    validity = model(input)\n",
    "\n",
    "    # return model\n",
    "    return Model(input, validity, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "train_X = train_X.astype(\"float32\") / 255\n",
    "test_X = test_X.astype(\"float32\") / 255\n",
    "\n",
    "train_X = np.expand_dims(train_X, -1)\n",
    "test_X = np.expand_dims(test_X, -1)\n",
    "\n",
    "train_y = to_categorical(train_y)\n",
    "test_y  = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Classifier; model to attack and later defend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (Conv2D)        (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 28)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 56)        14168     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 56)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 56)          28280     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 504)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 56)                28280     \n",
      "                                                                 \n",
      " classication_output (Dense)  (None, 10)               570       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,578\n",
      "Trainable params: 71,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'get_updates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m create_classifier()\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n\u001b[0;32m      8\u001b[0m clf \u001b[39m=\u001b[39m KerasClassifier(model\u001b[39m=\u001b[39mmodel)\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39msave_weights(\u001b[39m\"\u001b[39m\u001b[39mclassifier.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_v1.py:854\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    853\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    855\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    856\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    857\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    858\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    859\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    860\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    861\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    862\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    863\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    864\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    865\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    866\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    867\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    868\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    869\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    870\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    871\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m    872\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m    873\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m    874\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_steps` should not be specified if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_data` is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[39mreturn\u001b[39;00m fit_loop(\n\u001b[0;32m    735\u001b[0m     model,\n\u001b[0;32m    736\u001b[0m     inputs\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    737\u001b[0m     targets\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    738\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weights,\n\u001b[0;32m    739\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    740\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    741\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    742\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    743\u001b[0m     val_inputs\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m    744\u001b[0m     val_targets\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m    745\u001b[0m     val_sample_weights\u001b[39m=\u001b[39;49mval_sample_weights,\n\u001b[0;32m    746\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    747\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    748\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    749\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    750\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    751\u001b[0m     steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    752\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_arrays_v1.py:192\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m _update_sample_weight_mode(model, mode, ins)\n\u001b[0;32m    189\u001b[0m \u001b[39m# Get step function and loop type. As part of building the execution\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39m# function we recompile the metrics based on the updated\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39m# sample_weight_mode value.\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m f \u001b[39m=\u001b[39m _make_execution_function(model, mode)\n\u001b[0;32m    194\u001b[0m \u001b[39m# Prepare validation data. Hold references to the iterator and the input\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# list to properly reinitialize and reuse in multiple validation passes.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m val_iterator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_arrays_v1.py:620\u001b[0m, in \u001b[0;36m_make_execution_function\u001b[1;34m(model, mode)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39m_distribution_strategy:\n\u001b[0;32m    617\u001b[0m     \u001b[39mreturn\u001b[39;00m distributed_training_utils_v1\u001b[39m.\u001b[39m_make_execution_function(\n\u001b[0;32m    618\u001b[0m         model, mode\n\u001b[0;32m    619\u001b[0m     )\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49m_make_execution_function(mode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_v1.py:2364\u001b[0m, in \u001b[0;36mModel._make_execution_function\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_execution_function\u001b[39m(\u001b[39mself\u001b[39m, mode):\n\u001b[0;32m   2363\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m ModeKeys\u001b[39m.\u001b[39mTRAIN:\n\u001b[1;32m-> 2364\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_train_function()\n\u001b[0;32m   2365\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function\n\u001b[0;32m   2366\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m ModeKeys\u001b[39m.\u001b[39mTEST:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_v1.py:2282\u001b[0m, in \u001b[0;36mModel._make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2279\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mget_graph()\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m   2280\u001b[0m     \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2281\u001b[0m         \u001b[39m# Training updates\u001b[39;00m\n\u001b[1;32m-> 2282\u001b[0m         updates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mget_updates(\n\u001b[0;32m   2283\u001b[0m             params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collected_trainable_weights,\n\u001b[0;32m   2284\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_loss,\n\u001b[0;32m   2285\u001b[0m         )\n\u001b[0;32m   2286\u001b[0m         \u001b[39m# Unconditional updates\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m         updates \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_updates_for(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'get_updates'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "model = create_classifier()\n",
    "model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "clf = KerasClassifier(model=model)\n",
    "model.save_weights(\"classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phoebe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training_v1.py:2333: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3149255653381346, 0.0725]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models and input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"adv_generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " adv_generator_encoder (Sequent  (None, 56, 56, 124)  36780      ['input_28[0][0]']               \n",
      " ial)                                                                                             \n",
      "                                                                                                  \n",
      " resblock (Sequential)          multiple             834024      ['adv_generator_encoder[0][0]',  \n",
      "                                                                  'tf_op_layer_add_4[0][0]',      \n",
      "                                                                  'tf_op_layer_add_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf_op_layer_add_4 (TensorFlowO  [(None, 56, 56, 124  0          ['resblock[0][0]',               \n",
      " pLayer)                        )]                                'adv_generator_encoder[0][0]']  \n",
      "                                                                                                  \n",
      " tf_op_layer_add_5 (TensorFlowO  [(None, 56, 56, 124  0          ['resblock[1][0]',               \n",
      " pLayer)                        )]                                'tf_op_layer_add_4[0][0]']      \n",
      "                                                                                                  \n",
      " tf_op_layer_add_6 (TensorFlowO  [(None, 56, 56, 124  0          ['resblock[2][0]',               \n",
      " pLayer)                        )]                                'tf_op_layer_add_5[0][0]']      \n",
      "                                                                                                  \n",
      " adv_generator_decoder (Sequent  multiple            54945       ['tf_op_layer_add_6[0][0]']      \n",
      " ial)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 925,749\n",
      "Trainable params: 923,885\n",
      "Non-trainable params: 1,864\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (Conv2D)        (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 24, 24, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 22, 22, 124)       71548     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 22, 22, 124)      496       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 22, 22, 124)       0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 22, 22, 124)       0         \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 20, 20, 256)       285952    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 20, 20, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 20, 20, 256)       0         \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 102400)            0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 102400)            0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 64)                6553664   \n",
      "                                                                 \n",
      " validity_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,931,821\n",
      "Trainable params: 6,930,933\n",
      "Non-trainable params: 888\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"advGAN-net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " adv_generator (Functional)     (None, 28, 28, 1)    925749      ['image[0][0]']                  \n",
      "                                                                                                  \n",
      " tf_op_layer_Add_7 (TensorFlowO  [(None, 28, 28, 1)]  0          ['image[0][0]',                  \n",
      " pLayer)                                                          'adv_generator[0][0]']          \n",
      "                                                                                                  \n",
      " tf_op_layer_clip_by_value_1/Mi  [(None, 28, 28, 1)]  0          ['tf_op_layer_Add_7[0][0]']      \n",
      " nimum (TensorFlowOpLayer)                                                                        \n",
      "                                                                                                  \n",
      " tf_op_layer_clip_by_value_1 (T  [(None, 28, 28, 1)]  0          ['tf_op_layer_clip_by_value_1/Min\n",
      " ensorFlowOpLayer)                                               imum[0][0]']                     \n",
      "                                                                                                  \n",
      " discriminator (Functional)     (None, 1)            6931821     ['tf_op_layer_clip_by_value_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " mnist_classifier (Functional)  (None, 10)           71578       ['tf_op_layer_clip_by_value_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,929,148\n",
      "Trainable params: 923,885\n",
      "Non-trainable params: 7,005,263\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Values for advGAN ###\n",
    "alpha = 2\n",
    "beta = 1\n",
    "c = 0.1\n",
    "#########################\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "input = Input(shape=(28,28,1), name=\"image\")\n",
    "\n",
    "adv_generator = create_adv_generator()\n",
    "perturbations = adv_generator(input)\n",
    "\n",
    "adv_image = tf.add(input, perturbations)\n",
    "adv_image = tf.clip_by_value(adv_image, 0, 1) # Values in image is [0,1]\n",
    "\n",
    "# We want the generator and discriminator to be trained in a combined model but as seperate entities\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(adv_image)\n",
    "\n",
    "# We dont want to train our model to attack\n",
    "model.trainable = False\n",
    "prediction = model(adv_image)\n",
    "\n",
    "outputs_w_names = {\n",
    "    \"mnist_classifier\": prediction,\n",
    "    \"discriminator\": validity,\n",
    "    \"adv_generator\": perturbations,\n",
    "}\n",
    "\n",
    "advGAN_model = Model(inputs=input, outputs=outputs_w_names, name=\"advGAN-net\")\n",
    "\n",
    "class PerturbationLoss(Loss):\n",
    "  def call(self, y_true, y_pred):\n",
    "    # Colin Targonski (ctargon), Feb-2019, link: https://github.com/ctargon/AdvGAN-tf/blob/master/AdvGAN.py\n",
    "    zeros = tf.zeros((tf.shape(perturbations)[0]))\n",
    "    L_hinge = tf.reduce_mean(tf.maximum(zeros, tf.norm(tf.reshape(y_pred, (tf.shape(y_pred)[0], -1)), axis=1) - c))\n",
    "    return L_hinge\n",
    "\n",
    "L_adv = CategoricalCrossentropy()\n",
    "L_GAN = BinaryCrossentropy()\n",
    "L_hinge = PerturbationLoss()\n",
    "\n",
    "losses = {\n",
    "    \"mnist_classifier\": L_adv,\n",
    "    \"discriminator\": L_GAN,\n",
    "    \"adv_generator\": L_hinge,\n",
    "}\n",
    "\n",
    "losses_weights = {\n",
    "    \"mnist_classifier\": 1,\n",
    "    \"discriminator\": alpha,\n",
    "    \"adv_generator\": beta,\n",
    "}\n",
    "\n",
    "advGAN_model.compile(optimizer=optimizer, loss=losses, loss_weights=losses_weights, metrics=[\"accuracy\"])\n",
    "advGAN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdvGAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "EPOCH: 0\n",
      "Total loss = 23.87406349182129 \n",
      "\tLosses: adv_generator = 18.75961685180664, mnist_classifier = 0.6983170509338379, discriminator = 3.7178142070770264\n",
      "\tAccuracy: adv_generator = 5.9789541410282254e-05, mnist_classifier = 0.1328125, discriminator = 0.0 \n",
      "\n",
      "EPOCH: 1\n",
      "Total loss = 51.49748611450195 \n",
      "\tLosses: adv_generator = 24.983226776123047, mnist_classifier = 11.779269218444824, discriminator = 2.955721139907837\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1796875 \n",
      "\n",
      "EPOCH: 2\n",
      "Total loss = 56.79978561401367 \n",
      "\tLosses: adv_generator = 22.36715316772461, mnist_classifier = 16.202823638916016, discriminator = 2.026986598968506\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.4609375 \n",
      "\n",
      "EPOCH: 3\n",
      "Total loss = 21.311246871948242 \n",
      "\tLosses: adv_generator = 15.375489234924316, mnist_classifier = 0.6934405565261841, discriminator = 4.548875331878662\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.109375 \n",
      "\n",
      "EPOCH: 4\n",
      "Total loss = 20.255109786987305 \n",
      "\tLosses: adv_generator = 12.401505470275879, mnist_classifier = 0.6936282515525818, discriminator = 6.466348171234131\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.0859375 \n",
      "\n",
      "EPOCH: 5\n",
      "Total loss = 16.1600341796875 \n",
      "\tLosses: adv_generator = 12.61378288269043, mnist_classifier = 0.6937704682350159, discriminator = 2.1587114334106445\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3125 \n",
      "\n",
      "EPOCH: 6\n",
      "Total loss = 14.586392402648926 \n",
      "\tLosses: adv_generator = 11.023513793945312, mnist_classifier = 0.6938809156417847, discriminator = 2.175116539001465\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3359375 \n",
      "\n",
      "EPOCH: 7\n",
      "Total loss = 13.664145469665527 \n",
      "\tLosses: adv_generator = 8.4181489944458, mnist_classifier = 0.6939678192138672, discriminator = 3.8580610752105713\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.15625 \n",
      "\n",
      "EPOCH: 8\n",
      "Total loss = 12.349273681640625 \n",
      "\tLosses: adv_generator = 8.13601303100586, mnist_classifier = 0.6940354704856873, discriminator = 2.8251900672912598\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.109375 \n",
      "\n",
      "EPOCH: 9\n",
      "Total loss = 11.312323570251465 \n",
      "\tLosses: adv_generator = 6.549585819244385, mnist_classifier = 0.6940894722938538, discriminator = 3.374558687210083\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1640625 \n",
      "\n",
      "EPOCH: 10\n",
      "Total loss = 11.461238861083984 \n",
      "\tLosses: adv_generator = 6.386228561401367, mnist_classifier = 0.6941328048706055, discriminator = 3.6867446899414062\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.109375 \n",
      "\n",
      "EPOCH: 11\n",
      "Total loss = 11.32467269897461 \n",
      "\tLosses: adv_generator = 7.4808454513549805, mnist_classifier = 0.6941675543785095, discriminator = 2.4554924964904785\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.125 \n",
      "\n",
      "EPOCH: 12\n",
      "Total loss = 10.359620094299316 \n",
      "\tLosses: adv_generator = 5.670096397399902, mnist_classifier = 0.6941953897476196, discriminator = 3.301133394241333\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1015625 \n",
      "\n",
      "EPOCH: 13\n",
      "Total loss = 10.150274276733398 \n",
      "\tLosses: adv_generator = 5.15253210067749, mnist_classifier = 0.6942177414894104, discriminator = 3.609306573867798\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1328125 \n",
      "\n",
      "EPOCH: 14\n",
      "Total loss = 9.841175079345703 \n",
      "\tLosses: adv_generator = 5.724615573883057, mnist_classifier = 0.6942357420921326, discriminator = 2.7280876636505127\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.15625 \n",
      "\n",
      "EPOCH: 15\n",
      "Total loss = 9.85003662109375 \n",
      "\tLosses: adv_generator = 5.92642879486084, mnist_classifier = 0.6942500472068787, discriminator = 2.5351080894470215\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.2109375 \n",
      "\n",
      "EPOCH: 16\n",
      "Total loss = 9.889272689819336 \n",
      "\tLosses: adv_generator = 5.311514854431152, mnist_classifier = 0.6942613124847412, discriminator = 3.189235210418701\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.0859375 \n",
      "\n",
      "EPOCH: 17\n",
      "Total loss = 9.312263488769531 \n",
      "\tLosses: adv_generator = 5.316283226013184, mnist_classifier = 0.6942701935768127, discriminator = 2.6074395179748535\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1640625 \n",
      "\n",
      "EPOCH: 18\n",
      "Total loss = 9.432046890258789 \n",
      "\tLosses: adv_generator = 5.152066230773926, mnist_classifier = 0.6942772269248962, discriminator = 2.891425609588623\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1484375 \n",
      "\n",
      "EPOCH: 19\n",
      "Total loss = 9.563833236694336 \n",
      "\tLosses: adv_generator = 5.646480083465576, mnist_classifier = 0.694282591342926, discriminator = 2.528787612915039\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.140625 \n",
      "\n",
      "EPOCH: 20\n",
      "Total loss = 10.537311553955078 \n",
      "\tLosses: adv_generator = 6.101281642913818, mnist_classifier = 0.6942867636680603, discriminator = 3.0474562644958496\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1875 \n",
      "\n",
      "EPOCH: 21\n",
      "Total loss = 9.500923156738281 \n",
      "\tLosses: adv_generator = 6.387364387512207, mnist_classifier = 0.694290041923523, discriminator = 1.7249782085418701\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.421875 \n",
      "\n",
      "EPOCH: 22\n",
      "Total loss = 8.965688705444336 \n",
      "\tLosses: adv_generator = 5.53099250793457, mnist_classifier = 0.6942921280860901, discriminator = 2.046112060546875\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.2890625 \n",
      "\n",
      "EPOCH: 23\n",
      "Total loss = 9.793851852416992 \n",
      "\tLosses: adv_generator = 5.477512836456299, mnist_classifier = 0.694293737411499, discriminator = 2.9277515411376953\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.2265625 \n",
      "\n",
      "EPOCH: 24\n",
      "Total loss = 9.390079498291016 \n",
      "\tLosses: adv_generator = 5.932804584503174, mnist_classifier = 0.6942948698997498, discriminator = 2.0686848163604736\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.2890625 \n",
      "\n",
      "EPOCH: 25\n",
      "Total loss = 8.665958404541016 \n",
      "\tLosses: adv_generator = 5.518909454345703, mnist_classifier = 0.694295346736908, discriminator = 1.7584584951400757\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.390625 \n",
      "\n",
      "EPOCH: 26\n",
      "Total loss = 9.9584321975708 \n",
      "\tLosses: adv_generator = 6.264791488647461, mnist_classifier = 0.6942955255508423, discriminator = 2.3050498962402344\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.2421875 \n",
      "\n",
      "EPOCH: 27\n",
      "Total loss = 9.030655860900879 \n",
      "\tLosses: adv_generator = 5.02888822555542, mnist_classifier = 0.6942954659461975, discriminator = 2.6131770610809326\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1484375 \n",
      "\n",
      "EPOCH: 28\n",
      "Total loss = 8.944785118103027 \n",
      "\tLosses: adv_generator = 5.936534881591797, mnist_classifier = 0.6942950487136841, discriminator = 1.6196603775024414\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.40625 \n",
      "\n",
      "EPOCH: 29\n",
      "Total loss = 9.250061988830566 \n",
      "\tLosses: adv_generator = 5.846240520477295, mnist_classifier = 0.6942945122718811, discriminator = 2.015232563018799\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.234375 \n",
      "\n",
      "EPOCH: 30\n",
      "Total loss = 8.701848983764648 \n",
      "\tLosses: adv_generator = 5.634325981140137, mnist_classifier = 0.6942939162254333, discriminator = 1.6789352893829346\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.328125 \n",
      "\n",
      "EPOCH: 31\n",
      "Total loss = 8.684268951416016 \n",
      "\tLosses: adv_generator = 5.274893760681152, mnist_classifier = 0.6942930817604065, discriminator = 2.020789623260498\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.28125 \n",
      "\n",
      "EPOCH: 32\n",
      "Total loss = 8.842325210571289 \n",
      "\tLosses: adv_generator = 4.838961601257324, mnist_classifier = 0.6942921280860901, discriminator = 2.6147799491882324\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.203125 \n",
      "\n",
      "EPOCH: 33\n",
      "Total loss = 8.29946517944336 \n",
      "\tLosses: adv_generator = 5.422252178192139, mnist_classifier = 0.6942911148071289, discriminator = 1.4886302947998047\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.46875 \n",
      "\n",
      "EPOCH: 34\n",
      "Total loss = 8.405869483947754 \n",
      "\tLosses: adv_generator = 4.951066970825195, mnist_classifier = 0.6942901015281677, discriminator = 2.0662219524383545\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3125 \n",
      "\n",
      "EPOCH: 35\n",
      "Total loss = 8.757707595825195 \n",
      "\tLosses: adv_generator = 4.615965843200684, mnist_classifier = 0.6942887902259827, discriminator = 2.7531638145446777\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.1796875 \n",
      "\n",
      "EPOCH: 36\n",
      "Total loss = 8.77114200592041 \n",
      "\tLosses: adv_generator = 5.670710563659668, mnist_classifier = 0.6942877173423767, discriminator = 1.7118556499481201\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3515625 \n",
      "\n",
      "EPOCH: 37\n",
      "Total loss = 8.05489444732666 \n",
      "\tLosses: adv_generator = 5.370615005493164, mnist_classifier = 0.6942864060401917, discriminator = 1.2957067489624023\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5546875 \n",
      "\n",
      "EPOCH: 38\n",
      "Total loss = 8.879012107849121 \n",
      "\tLosses: adv_generator = 5.574462413787842, mnist_classifier = 0.6942851543426514, discriminator = 1.9159791469573975\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.359375 \n",
      "\n",
      "EPOCH: 39\n",
      "Total loss = 8.95737361907959 \n",
      "\tLosses: adv_generator = 5.8788628578186035, mnist_classifier = 0.6942839026451111, discriminator = 1.6899428367614746\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3359375 \n",
      "\n",
      "EPOCH: 40\n",
      "Total loss = 8.1782865524292 \n",
      "\tLosses: adv_generator = 5.6766581535339355, mnist_classifier = 0.694282591342926, discriminator = 1.113063097000122\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.625 \n",
      "\n",
      "EPOCH: 41\n",
      "Total loss = 9.686233520507812 \n",
      "\tLosses: adv_generator = 6.309853553771973, mnist_classifier = 0.6942813396453857, discriminator = 1.9878168106079102\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.2890625 \n",
      "\n",
      "EPOCH: 42\n",
      "Total loss = 8.242244720458984 \n",
      "\tLosses: adv_generator = 5.264305114746094, mnist_classifier = 0.6942800283432007, discriminator = 1.5893797874450684\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3828125 \n",
      "\n",
      "EPOCH: 43\n",
      "Total loss = 9.617356300354004 \n",
      "\tLosses: adv_generator = 7.1026740074157715, mnist_classifier = 0.6942786574363708, discriminator = 1.1261255741119385\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.609375 \n",
      "\n",
      "EPOCH: 44\n",
      "Total loss = 8.191017150878906 \n",
      "\tLosses: adv_generator = 5.262704372406006, mnist_classifier = 0.694277286529541, discriminator = 1.5397586822509766\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.40625 \n",
      "\n",
      "EPOCH: 45\n",
      "Total loss = 9.850582122802734 \n",
      "\tLosses: adv_generator = 6.468799591064453, mnist_classifier = 0.6942759156227112, discriminator = 1.993231177330017\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3203125 \n",
      "\n",
      "EPOCH: 46\n",
      "Total loss = 8.063478469848633 \n",
      "\tLosses: adv_generator = 5.699968338012695, mnist_classifier = 0.6942745447158813, discriminator = 0.9749617576599121\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.65625 \n",
      "\n",
      "EPOCH: 47\n",
      "Total loss = 9.392698287963867 \n",
      "\tLosses: adv_generator = 6.97283411026001, mnist_classifier = 0.6942733526229858, discriminator = 1.0313177108764648\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6953125 \n",
      "\n",
      "EPOCH: 48\n",
      "Total loss = 8.42414379119873 \n",
      "\tLosses: adv_generator = 5.338232517242432, mnist_classifier = 0.694271981716156, discriminator = 1.6973669528961182\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.421875 \n",
      "\n",
      "EPOCH: 49\n",
      "Total loss = 9.586113929748535 \n",
      "\tLosses: adv_generator = 6.260470867156982, mnist_classifier = 0.6942705512046814, discriminator = 1.9371014833450317\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.375 \n",
      "\n",
      "EPOCH: 50\n",
      "Total loss = 8.734238624572754 \n",
      "\tLosses: adv_generator = 5.95063591003418, mnist_classifier = 0.6942691802978516, discriminator = 1.3950639963150024\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5234375 \n",
      "\n",
      "EPOCH: 51\n",
      "Total loss = 9.562033653259277 \n",
      "\tLosses: adv_generator = 7.3557257652282715, mnist_classifier = 0.6942678093910217, discriminator = 0.8177721500396729\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7421875 \n",
      "\n",
      "EPOCH: 52\n",
      "Total loss = 9.59797477722168 \n",
      "\tLosses: adv_generator = 6.581546783447266, mnist_classifier = 0.6942665576934814, discriminator = 1.627894639968872\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.390625 \n",
      "\n",
      "EPOCH: 53\n",
      "Total loss = 8.465917587280273 \n",
      "\tLosses: adv_generator = 5.358099937438965, mnist_classifier = 0.6942653059959412, discriminator = 1.7192869186401367\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.4296875 \n",
      "\n",
      "EPOCH: 54\n",
      "Total loss = 9.278724670410156 \n",
      "\tLosses: adv_generator = 6.1420440673828125, mnist_classifier = 0.6942638754844666, discriminator = 1.7481523752212524\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.3515625 \n",
      "\n",
      "EPOCH: 55\n",
      "Total loss = 7.498251438140869 \n",
      "\tLosses: adv_generator = 5.237706184387207, mnist_classifier = 0.6942625641822815, discriminator = 0.8720201253890991\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.703125 \n",
      "\n",
      "EPOCH: 56\n",
      "Total loss = 8.850334167480469 \n",
      "\tLosses: adv_generator = 6.038290023803711, mnist_classifier = 0.6942611932754517, discriminator = 1.4235215187072754\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.4921875 \n",
      "\n",
      "EPOCH: 57\n",
      "Total loss = 7.539552688598633 \n",
      "\tLosses: adv_generator = 5.180088996887207, mnist_classifier = 0.694259762763977, discriminator = 0.9709442853927612\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6640625 \n",
      "\n",
      "EPOCH: 58\n",
      "Total loss = 8.252532005310059 \n",
      "\tLosses: adv_generator = 5.55171012878418, mnist_classifier = 0.6942585706710815, discriminator = 1.3123047351837158\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.4921875 \n",
      "\n",
      "EPOCH: 59\n",
      "Total loss = 7.705157279968262 \n",
      "\tLosses: adv_generator = 5.360052108764648, mnist_classifier = 0.6942571997642517, discriminator = 0.9565908908843994\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.65625 \n",
      "\n",
      "EPOCH: 60\n",
      "Total loss = 8.085251808166504 \n",
      "\tLosses: adv_generator = 5.617135047912598, mnist_classifier = 0.6942558288574219, discriminator = 1.0796051025390625\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6171875 \n",
      "\n",
      "EPOCH: 61\n",
      "Total loss = 7.626974105834961 \n",
      "\tLosses: adv_generator = 4.749271392822266, mnist_classifier = 0.694254457950592, discriminator = 1.4891941547393799\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.4765625 \n",
      "\n",
      "EPOCH: 62\n",
      "Total loss = 7.771920204162598 \n",
      "\tLosses: adv_generator = 4.146312236785889, mnist_classifier = 0.6942530870437622, discriminator = 2.2371013164520264\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.265625 \n",
      "\n",
      "EPOCH: 63\n",
      "Total loss = 7.55908203125 \n",
      "\tLosses: adv_generator = 5.01686954498291, mnist_classifier = 0.6942518949508667, discriminator = 1.1537083387374878\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6015625 \n",
      "\n",
      "EPOCH: 64\n",
      "Total loss = 7.080660343170166 \n",
      "\tLosses: adv_generator = 4.9177751541137695, mnist_classifier = 0.6942505240440369, discriminator = 0.7743841409683228\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 65\n",
      "Total loss = 7.651424407958984 \n",
      "\tLosses: adv_generator = 4.830733299255371, mnist_classifier = 0.694249153137207, discriminator = 1.4321926832199097\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.390625 \n",
      "\n",
      "EPOCH: 66\n",
      "Total loss = 6.997837066650391 \n",
      "\tLosses: adv_generator = 4.565378189086914, mnist_classifier = 0.6942477822303772, discriminator = 1.0439634323120117\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.578125 \n",
      "\n",
      "EPOCH: 67\n",
      "Total loss = 7.159875869750977 \n",
      "\tLosses: adv_generator = 4.963438987731934, mnist_classifier = 0.6942464113235474, discriminator = 0.8079444169998169\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.703125 \n",
      "\n",
      "EPOCH: 68\n",
      "Total loss = 7.024592399597168 \n",
      "\tLosses: adv_generator = 4.631547451019287, mnist_classifier = 0.6942452192306519, discriminator = 1.0045545101165771\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6328125 \n",
      "\n",
      "EPOCH: 69\n",
      "Total loss = 6.803826332092285 \n",
      "\tLosses: adv_generator = 4.39353084564209, mnist_classifier = 0.694243848323822, discriminator = 1.0218076705932617\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6796875 \n",
      "\n",
      "EPOCH: 70\n",
      "Total loss = 7.051739692687988 \n",
      "\tLosses: adv_generator = 4.300838947296143, mnist_classifier = 0.6942424774169922, discriminator = 1.3624155521392822\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5546875 \n",
      "\n",
      "EPOCH: 71\n",
      "Total loss = 6.425082206726074 \n",
      "\tLosses: adv_generator = 4.052643775939941, mnist_classifier = 0.6942411065101624, discriminator = 0.9839563369750977\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.640625 \n",
      "\n",
      "EPOCH: 72\n",
      "Total loss = 6.748016834259033 \n",
      "\tLosses: adv_generator = 4.600271224975586, mnist_classifier = 0.6942398548126221, discriminator = 0.7592659592628479\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.75 \n",
      "\n",
      "EPOCH: 73\n",
      "Total loss = 6.507758140563965 \n",
      "\tLosses: adv_generator = 4.275811195373535, mnist_classifier = 0.6942386031150818, discriminator = 0.8434698581695557\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7109375 \n",
      "\n",
      "EPOCH: 74\n",
      "Total loss = 6.588114261627197 \n",
      "\tLosses: adv_generator = 4.233764171600342, mnist_classifier = 0.694237232208252, discriminator = 0.9658758044242859\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.640625 \n",
      "\n",
      "EPOCH: 75\n",
      "Total loss = 6.851787567138672 \n",
      "\tLosses: adv_generator = 4.607523441314697, mnist_classifier = 0.6942359209060669, discriminator = 0.8557920455932617\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6640625 \n",
      "\n",
      "EPOCH: 76\n",
      "Total loss = 6.6390557289123535 \n",
      "\tLosses: adv_generator = 4.325100421905518, mnist_classifier = 0.6942346096038818, discriminator = 0.9254859089851379\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.671875 \n",
      "\n",
      "EPOCH: 77\n",
      "Total loss = 6.4659624099731445 \n",
      "\tLosses: adv_generator = 4.443565845489502, mnist_classifier = 0.6942333579063416, discriminator = 0.633929967880249\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 78\n",
      "Total loss = 6.296888828277588 \n",
      "\tLosses: adv_generator = 4.234025955200195, mnist_classifier = 0.6942320466041565, discriminator = 0.6743987798690796\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.765625 \n",
      "\n",
      "EPOCH: 79\n",
      "Total loss = 6.658734321594238 \n",
      "\tLosses: adv_generator = 4.009986400604248, mnist_classifier = 0.6942306160926819, discriminator = 1.2602869272232056\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5390625 \n",
      "\n",
      "EPOCH: 80\n",
      "Total loss = 7.390831470489502 \n",
      "\tLosses: adv_generator = 5.460248947143555, mnist_classifier = 0.6942294836044312, discriminator = 0.5421233773231506\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 81\n",
      "Total loss = 6.452933311462402 \n",
      "\tLosses: adv_generator = 4.331376075744629, mnist_classifier = 0.6942281126976013, discriminator = 0.7331010103225708\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 82\n",
      "Total loss = 6.371823787689209 \n",
      "\tLosses: adv_generator = 4.119950294494629, mnist_classifier = 0.6942268013954163, discriminator = 0.8634198904037476\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.65625 \n",
      "\n",
      "EPOCH: 83\n",
      "Total loss = 6.8907928466796875 \n",
      "\tLosses: adv_generator = 4.924385070800781, mnist_classifier = 0.6942254304885864, discriminator = 0.5779569149017334\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 84\n",
      "Total loss = 6.574532985687256 \n",
      "\tLosses: adv_generator = 4.17702579498291, mnist_classifier = 0.6942242980003357, discriminator = 1.0090584754943848\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.671875 \n",
      "\n",
      "EPOCH: 85\n",
      "Total loss = 6.3653035163879395 \n",
      "\tLosses: adv_generator = 4.391547203063965, mnist_classifier = 0.6942229866981506, discriminator = 0.5853104591369629\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 86\n",
      "Total loss = 6.326963424682617 \n",
      "\tLosses: adv_generator = 4.408376693725586, mnist_classifier = 0.694221556186676, discriminator = 0.5301439762115479\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 87\n",
      "Total loss = 6.409301280975342 \n",
      "\tLosses: adv_generator = 3.9716436862945557, mnist_classifier = 0.6942204236984253, discriminator = 1.0492167472839355\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6328125 \n",
      "\n",
      "EPOCH: 88\n",
      "Total loss = 6.7880377769470215 \n",
      "\tLosses: adv_generator = 4.526462554931641, mnist_classifier = 0.6942190527915955, discriminator = 0.8731368780136108\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.671875 \n",
      "\n",
      "EPOCH: 89\n",
      "Total loss = 6.227989196777344 \n",
      "\tLosses: adv_generator = 4.161238193511963, mnist_classifier = 0.6942177414894104, discriminator = 0.6783158779144287\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 90\n",
      "Total loss = 6.366818904876709 \n",
      "\tLosses: adv_generator = 4.326333045959473, mnist_classifier = 0.6942164897918701, discriminator = 0.6520528793334961\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 91\n",
      "Total loss = 6.655457496643066 \n",
      "\tLosses: adv_generator = 4.725324630737305, mnist_classifier = 0.6942152380943298, discriminator = 0.5417022705078125\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 92\n",
      "Total loss = 6.271168231964111 \n",
      "\tLosses: adv_generator = 3.9592230319976807, mnist_classifier = 0.6942139267921448, discriminator = 0.9235172867774963\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6328125 \n",
      "\n",
      "EPOCH: 93\n",
      "Total loss = 6.166723251342773 \n",
      "\tLosses: adv_generator = 4.165667533874512, mnist_classifier = 0.6942126750946045, discriminator = 0.6126303672790527\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 94\n",
      "Total loss = 6.230781078338623 \n",
      "\tLosses: adv_generator = 4.404012203216553, mnist_classifier = 0.694211483001709, discriminator = 0.438345730304718\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 95\n",
      "Total loss = 6.853067398071289 \n",
      "\tLosses: adv_generator = 3.855205535888672, mnist_classifier = 0.6942101120948792, discriminator = 1.6094419956207275\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.421875 \n",
      "\n",
      "EPOCH: 96\n",
      "Total loss = 7.156542778015137 \n",
      "\tLosses: adv_generator = 5.444975852966309, mnist_classifier = 0.6942089796066284, discriminator = 0.32314878702163696\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.953125 \n",
      "\n",
      "EPOCH: 97\n",
      "Total loss = 6.6036224365234375 \n",
      "\tLosses: adv_generator = 4.762039661407471, mnist_classifier = 0.6942076086997986, discriminator = 0.45316749811172485\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 98\n",
      "Total loss = 7.319957733154297 \n",
      "\tLosses: adv_generator = 5.070878028869629, mnist_classifier = 0.6942063570022583, discriminator = 0.8606671094894409\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.671875 \n",
      "\n",
      "EPOCH: 99\n",
      "Total loss = 6.423084735870361 \n",
      "\tLosses: adv_generator = 4.591723442077637, mnist_classifier = 0.6942051649093628, discriminator = 0.4429508149623871\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 100\n",
      "Total loss = 6.3813157081604 \n",
      "\tLosses: adv_generator = 4.124464988708496, mnist_classifier = 0.6942038536071777, discriminator = 0.8684428930282593\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6796875 \n",
      "\n",
      "EPOCH: 101\n",
      "Total loss = 7.029477596282959 \n",
      "\tLosses: adv_generator = 4.5404510498046875, mnist_classifier = 0.6942024827003479, discriminator = 1.1006218194961548\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5390625 \n",
      "\n",
      "EPOCH: 102\n",
      "Total loss = 7.008749008178711 \n",
      "\tLosses: adv_generator = 5.315449237823486, mnist_classifier = 0.6942014098167419, discriminator = 0.30489692091941833\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 103\n",
      "Total loss = 6.909754753112793 \n",
      "\tLosses: adv_generator = 5.175468921661377, mnist_classifier = 0.6942000389099121, discriminator = 0.3458859920501709\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 104\n",
      "Total loss = 7.309818267822266 \n",
      "\tLosses: adv_generator = 4.845951080322266, mnist_classifier = 0.694198727607727, discriminator = 1.075469732284546\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5859375 \n",
      "\n",
      "EPOCH: 105\n",
      "Total loss = 6.190789699554443 \n",
      "\tLosses: adv_generator = 4.027303695678711, mnist_classifier = 0.6941975951194763, discriminator = 0.7750908136367798\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6953125 \n",
      "\n",
      "EPOCH: 106\n",
      "Total loss = 6.385146617889404 \n",
      "\tLosses: adv_generator = 4.397435665130615, mnist_classifier = 0.6941962838172913, discriminator = 0.5993186235427856\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.765625 \n",
      "\n",
      "EPOCH: 107\n",
      "Total loss = 6.6280717849731445 \n",
      "\tLosses: adv_generator = 4.643185138702393, mnist_classifier = 0.694195032119751, discriminator = 0.5964965224266052\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 108\n",
      "Total loss = 6.115776062011719 \n",
      "\tLosses: adv_generator = 4.300127029418945, mnist_classifier = 0.6941938400268555, discriminator = 0.42726123332977295\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 109\n",
      "Total loss = 6.363615989685059 \n",
      "\tLosses: adv_generator = 4.498403549194336, mnist_classifier = 0.6941924691200256, discriminator = 0.4768276810646057\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 110\n",
      "Total loss = 6.3367085456848145 \n",
      "\tLosses: adv_generator = 3.752504348754883, mnist_classifier = 0.6941913366317749, discriminator = 1.1958212852478027\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5390625 \n",
      "\n",
      "EPOCH: 111\n",
      "Total loss = 6.030581474304199 \n",
      "\tLosses: adv_generator = 4.084181308746338, mnist_classifier = 0.6941900849342346, discriminator = 0.5580198764801025\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 112\n",
      "Total loss = 6.054872035980225 \n",
      "\tLosses: adv_generator = 4.219939708709717, mnist_classifier = 0.6941887140274048, discriminator = 0.44655460119247437\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 113\n",
      "Total loss = 6.033875942230225 \n",
      "\tLosses: adv_generator = 3.8559532165527344, mnist_classifier = 0.694187581539154, discriminator = 0.7895476222038269\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.75 \n",
      "\n",
      "EPOCH: 114\n",
      "Total loss = 5.877653121948242 \n",
      "\tLosses: adv_generator = 3.7350547313690186, mnist_classifier = 0.694186270236969, discriminator = 0.754225492477417\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6640625 \n",
      "\n",
      "EPOCH: 115\n",
      "Total loss = 5.977824687957764 \n",
      "\tLosses: adv_generator = 3.9584689140319824, mnist_classifier = 0.6941851377487183, discriminator = 0.6309858560562134\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 116\n",
      "Total loss = 5.956615924835205 \n",
      "\tLosses: adv_generator = 3.8618149757385254, mnist_classifier = 0.6941838264465332, discriminator = 0.7064334154129028\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.75 \n",
      "\n",
      "EPOCH: 117\n",
      "Total loss = 5.917478561401367 \n",
      "\tLosses: adv_generator = 3.907792806625366, mnist_classifier = 0.6941826343536377, discriminator = 0.6213205456733704\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 118\n",
      "Total loss = 5.931449890136719 \n",
      "\tLosses: adv_generator = 3.66831111907959, mnist_classifier = 0.6941813826560974, discriminator = 0.8747760057449341\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.625 \n",
      "\n",
      "EPOCH: 119\n",
      "Total loss = 5.858997821807861 \n",
      "\tLosses: adv_generator = 3.9681055545806885, mnist_classifier = 0.6941801309585571, discriminator = 0.5025320649147034\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 120\n",
      "Total loss = 5.814229965209961 \n",
      "\tLosses: adv_generator = 3.8992080688476562, mnist_classifier = 0.6941789984703064, discriminator = 0.5266639590263367\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 121\n",
      "Total loss = 5.82009744644165 \n",
      "\tLosses: adv_generator = 3.8595049381256104, mnist_classifier = 0.6941776871681213, discriminator = 0.5722371935844421\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 122\n",
      "Total loss = 5.896430492401123 \n",
      "\tLosses: adv_generator = 3.686847686767578, mnist_classifier = 0.694176435470581, discriminator = 0.8212301135063171\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6640625 \n",
      "\n",
      "EPOCH: 123\n",
      "Total loss = 5.860401153564453 \n",
      "\tLosses: adv_generator = 3.9145495891571045, mnist_classifier = 0.6941752433776855, discriminator = 0.557500958442688\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 124\n",
      "Total loss = 5.840793609619141 \n",
      "\tLosses: adv_generator = 3.762399673461914, mnist_classifier = 0.69417405128479, discriminator = 0.6900460720062256\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.75 \n",
      "\n",
      "EPOCH: 125\n",
      "Total loss = 5.799863815307617 \n",
      "\tLosses: adv_generator = 3.7198078632354736, mnist_classifier = 0.6941728591918945, discriminator = 0.6917105317115784\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 126\n",
      "Total loss = 5.741675853729248 \n",
      "\tLosses: adv_generator = 3.7031917572021484, mnist_classifier = 0.6941715478897095, discriminator = 0.6501412391662598\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 127\n",
      "Total loss = 5.615236282348633 \n",
      "\tLosses: adv_generator = 3.669965982437134, mnist_classifier = 0.6941704154014587, discriminator = 0.5569295883178711\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 128\n",
      "Total loss = 5.729024887084961 \n",
      "\tLosses: adv_generator = 3.6668508052825928, mnist_classifier = 0.6941691040992737, discriminator = 0.6738355755805969\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 129\n",
      "Total loss = 5.63563346862793 \n",
      "\tLosses: adv_generator = 3.7434585094451904, mnist_classifier = 0.6941680312156677, discriminator = 0.5038388967514038\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 130\n",
      "Total loss = 5.684700965881348 \n",
      "\tLosses: adv_generator = 3.6575169563293457, mnist_classifier = 0.6941667199134827, discriminator = 0.6388506889343262\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 131\n",
      "Total loss = 5.748793125152588 \n",
      "\tLosses: adv_generator = 3.6173033714294434, mnist_classifier = 0.6941656470298767, discriminator = 0.7431583404541016\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6875 \n",
      "\n",
      "EPOCH: 132\n",
      "Total loss = 5.8533430099487305 \n",
      "\tLosses: adv_generator = 4.12982702255249, mnist_classifier = 0.6941643357276917, discriminator = 0.3351875841617584\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 133\n",
      "Total loss = 5.752357482910156 \n",
      "\tLosses: adv_generator = 3.755340576171875, mnist_classifier = 0.6941632032394409, discriminator = 0.6086904406547546\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 134\n",
      "Total loss = 5.653561592102051 \n",
      "\tLosses: adv_generator = 3.749575614929199, mnist_classifier = 0.6941618919372559, discriminator = 0.5156623125076294\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 135\n",
      "Total loss = 5.637640476226807 \n",
      "\tLosses: adv_generator = 3.5765585899353027, mnist_classifier = 0.6941608190536499, discriminator = 0.6727606058120728\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.71875 \n",
      "\n",
      "EPOCH: 136\n",
      "Total loss = 5.901464939117432 \n",
      "\tLosses: adv_generator = 3.8273749351501465, mnist_classifier = 0.6941595673561096, discriminator = 0.6857709884643555\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.71875 \n",
      "\n",
      "EPOCH: 137\n",
      "Total loss = 6.030697822570801 \n",
      "\tLosses: adv_generator = 4.096118927001953, mnist_classifier = 0.6941584348678589, discriminator = 0.5462616682052612\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 138\n",
      "Total loss = 5.8322858810424805 \n",
      "\tLosses: adv_generator = 3.8926656246185303, mnist_classifier = 0.6941571235656738, discriminator = 0.551305890083313\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 139\n",
      "Total loss = 5.622448921203613 \n",
      "\tLosses: adv_generator = 3.6899209022521973, mnist_classifier = 0.6941560506820679, discriminator = 0.5442160367965698\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 140\n",
      "Total loss = 6.0161848068237305 \n",
      "\tLosses: adv_generator = 3.9005284309387207, mnist_classifier = 0.6941547989845276, discriminator = 0.7273471355438232\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.703125 \n",
      "\n",
      "EPOCH: 141\n",
      "Total loss = 5.936584949493408 \n",
      "\tLosses: adv_generator = 4.091099739074707, mnist_classifier = 0.6941537261009216, discriminator = 0.4571775794029236\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 142\n",
      "Total loss = 5.751824378967285 \n",
      "\tLosses: adv_generator = 3.8715860843658447, mnist_classifier = 0.6941524147987366, discriminator = 0.4919331669807434\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 143\n",
      "Total loss = 5.660213470458984 \n",
      "\tLosses: adv_generator = 3.7415595054626465, mnist_classifier = 0.6941513419151306, discriminator = 0.5303511619567871\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 144\n",
      "Total loss = 6.133055210113525 \n",
      "\tLosses: adv_generator = 3.7684834003448486, mnist_classifier = 0.6941500306129456, discriminator = 0.9762715101242065\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5390625 \n",
      "\n",
      "EPOCH: 145\n",
      "Total loss = 6.523715496063232 \n",
      "\tLosses: adv_generator = 4.748166561126709, mnist_classifier = 0.6941489577293396, discriminator = 0.387251079082489\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 146\n",
      "Total loss = 5.931417465209961 \n",
      "\tLosses: adv_generator = 4.156691074371338, mnist_classifier = 0.6941476464271545, discriminator = 0.3864312767982483\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 147\n",
      "Total loss = 6.395485877990723 \n",
      "\tLosses: adv_generator = 4.273754119873047, mnist_classifier = 0.6941465735435486, discriminator = 0.7334383726119995\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.640625 \n",
      "\n",
      "EPOCH: 148\n",
      "Total loss = 6.197062969207764 \n",
      "\tLosses: adv_generator = 4.287336349487305, mnist_classifier = 0.6941452622413635, discriminator = 0.5214360356330872\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 149\n",
      "Total loss = 5.646575450897217 \n",
      "\tLosses: adv_generator = 3.7391600608825684, mnist_classifier = 0.6941441893577576, discriminator = 0.5191267132759094\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 150\n",
      "Total loss = 6.504883766174316 \n",
      "\tLosses: adv_generator = 4.2683610916137695, mnist_classifier = 0.6941429376602173, discriminator = 0.8482369184494019\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.625 \n",
      "\n",
      "EPOCH: 151\n",
      "Total loss = 6.683828353881836 \n",
      "\tLosses: adv_generator = 4.953069686889648, mnist_classifier = 0.6941418051719666, discriminator = 0.34247469902038574\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9375 \n",
      "\n",
      "EPOCH: 152\n",
      "Total loss = 5.947309970855713 \n",
      "\tLosses: adv_generator = 4.170802116394043, mnist_classifier = 0.6941405534744263, discriminator = 0.3882269859313965\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 153\n",
      "Total loss = 7.215505599975586 \n",
      "\tLosses: adv_generator = 4.706365585327148, mnist_classifier = 0.6941394805908203, discriminator = 1.1208611726760864\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5234375 \n",
      "\n",
      "EPOCH: 154\n",
      "Total loss = 5.792074203491211 \n",
      "\tLosses: adv_generator = 4.026738166809082, mnist_classifier = 0.6941384077072144, discriminator = 0.3770591616630554\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 155\n",
      "Total loss = 6.413020610809326 \n",
      "\tLosses: adv_generator = 4.577091217041016, mnist_classifier = 0.6941371560096741, discriminator = 0.44765517115592957\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 156\n",
      "Total loss = 5.8342132568359375 \n",
      "\tLosses: adv_generator = 3.9895401000976562, mnist_classifier = 0.6941360235214233, discriminator = 0.45640087127685547\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 157\n",
      "Total loss = 6.119903087615967 \n",
      "\tLosses: adv_generator = 3.698732852935791, mnist_classifier = 0.6941347718238831, discriminator = 1.0329008102416992\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.546875 \n",
      "\n",
      "EPOCH: 158\n",
      "Total loss = 6.136185169219971 \n",
      "\tLosses: adv_generator = 4.452713966369629, mnist_classifier = 0.6941336989402771, discriminator = 0.2952038645744324\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 159\n",
      "Total loss = 5.863324165344238 \n",
      "\tLosses: adv_generator = 4.043256759643555, mnist_classifier = 0.6941324472427368, discriminator = 0.431802898645401\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 160\n",
      "Total loss = 6.1448798179626465 \n",
      "\tLosses: adv_generator = 4.160838603973389, mnist_classifier = 0.6941313147544861, discriminator = 0.5957786440849304\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 161\n",
      "Total loss = 5.94174337387085 \n",
      "\tLosses: adv_generator = 3.9712769985198975, mnist_classifier = 0.6941301822662354, discriminator = 0.5822062492370605\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 162\n",
      "Total loss = 5.759069919586182 \n",
      "\tLosses: adv_generator = 3.714660167694092, mnist_classifier = 0.6941289901733398, discriminator = 0.6561517715454102\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 163\n",
      "Total loss = 6.3471455574035645 \n",
      "\tLosses: adv_generator = 4.253748893737793, mnist_classifier = 0.6941279172897339, discriminator = 0.7051407694816589\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 164\n",
      "Total loss = 5.7402567863464355 \n",
      "\tLosses: adv_generator = 3.931501865386963, mnist_classifier = 0.6941266655921936, discriminator = 0.42050158977508545\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 165\n",
      "Total loss = 5.722955226898193 \n",
      "\tLosses: adv_generator = 3.80301833152771, mnist_classifier = 0.6941255927085876, discriminator = 0.5316859483718872\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 166\n",
      "Total loss = 6.06749153137207 \n",
      "\tLosses: adv_generator = 3.9833381175994873, mnist_classifier = 0.6941243410110474, discriminator = 0.6959046125411987\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.734375 \n",
      "\n",
      "EPOCH: 167\n",
      "Total loss = 5.6426568031311035 \n",
      "\tLosses: adv_generator = 3.8871984481811523, mnist_classifier = 0.6941232681274414, discriminator = 0.3672119379043579\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 168\n",
      "Total loss = 5.792054176330566 \n",
      "\tLosses: adv_generator = 3.8988475799560547, mnist_classifier = 0.6941220760345459, discriminator = 0.5049624443054199\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 169\n",
      "Total loss = 5.7525482177734375 \n",
      "\tLosses: adv_generator = 3.7664871215820312, mnist_classifier = 0.6941209435462952, discriminator = 0.5978192090988159\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 170\n",
      "Total loss = 5.589437007904053 \n",
      "\tLosses: adv_generator = 3.5755162239074707, mnist_classifier = 0.6941198706626892, discriminator = 0.6256809234619141\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 171\n",
      "Total loss = 5.417611598968506 \n",
      "\tLosses: adv_generator = 3.626816749572754, mnist_classifier = 0.6941186189651489, discriminator = 0.40255773067474365\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 172\n",
      "Total loss = 5.578652381896973 \n",
      "\tLosses: adv_generator = 3.6599295139312744, mnist_classifier = 0.694117546081543, discriminator = 0.5304882526397705\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 173\n",
      "Total loss = 5.720914363861084 \n",
      "\tLosses: adv_generator = 3.6297459602355957, mnist_classifier = 0.694116473197937, discriminator = 0.7029356956481934\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 174\n",
      "Total loss = 5.742979049682617 \n",
      "\tLosses: adv_generator = 3.6951980590820312, mnist_classifier = 0.6941152215003967, discriminator = 0.6595507860183716\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 175\n",
      "Total loss = 5.552277565002441 \n",
      "\tLosses: adv_generator = 3.65287446975708, mnist_classifier = 0.6941141486167908, discriminator = 0.5111746191978455\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 176\n",
      "Total loss = 5.670766353607178 \n",
      "\tLosses: adv_generator = 3.622408866882324, mnist_classifier = 0.6941128969192505, discriminator = 0.6601318717002869\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 177\n",
      "Total loss = 5.473246097564697 \n",
      "\tLosses: adv_generator = 3.7229037284851074, mnist_classifier = 0.6941118240356445, discriminator = 0.3621189296245575\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9140625 \n",
      "\n",
      "EPOCH: 178\n",
      "Total loss = 5.494032382965088 \n",
      "\tLosses: adv_generator = 3.5077695846557617, mnist_classifier = 0.6941108107566833, discriminator = 0.5980410575866699\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 179\n",
      "Total loss = 5.3168840408325195 \n",
      "\tLosses: adv_generator = 3.4593653678894043, mnist_classifier = 0.6941095590591431, discriminator = 0.4692993760108948\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 180\n",
      "Total loss = 5.414566516876221 \n",
      "\tLosses: adv_generator = 3.5161361694335938, mnist_classifier = 0.6941084861755371, discriminator = 0.5102134943008423\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 181\n",
      "Total loss = 5.442368507385254 \n",
      "\tLosses: adv_generator = 3.4790658950805664, mnist_classifier = 0.6941074132919312, discriminator = 0.575087308883667\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 182\n",
      "Total loss = 5.513730525970459 \n",
      "\tLosses: adv_generator = 3.473412036895752, mnist_classifier = 0.6941062211990356, discriminator = 0.652105987071991\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 183\n",
      "Total loss = 5.577880382537842 \n",
      "\tLosses: adv_generator = 3.524463176727295, mnist_classifier = 0.6941050887107849, discriminator = 0.665207028388977\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 184\n",
      "Total loss = 5.487107753753662 \n",
      "\tLosses: adv_generator = 3.6123807430267334, mnist_classifier = 0.6941040754318237, discriminator = 0.4865190386772156\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 185\n",
      "Total loss = 5.319736957550049 \n",
      "\tLosses: adv_generator = 3.537052631378174, mnist_classifier = 0.6941028237342834, discriminator = 0.39447861909866333\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 186\n",
      "Total loss = 5.669774055480957 \n",
      "\tLosses: adv_generator = 3.534247875213623, mnist_classifier = 0.6941017508506775, discriminator = 0.7473224997520447\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7109375 \n",
      "\n",
      "EPOCH: 187\n",
      "Total loss = 5.550697326660156 \n",
      "\tLosses: adv_generator = 3.454416275024414, mnist_classifier = 0.6941006183624268, discriminator = 0.7080796957015991\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7421875 \n",
      "\n",
      "EPOCH: 188\n",
      "Total loss = 5.6725006103515625 \n",
      "\tLosses: adv_generator = 3.8625597953796387, mnist_classifier = 0.694099485874176, discriminator = 0.42174214124679565\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 189\n",
      "Total loss = 5.553469657897949 \n",
      "\tLosses: adv_generator = 3.5764107704162598, mnist_classifier = 0.6940984129905701, discriminator = 0.5888620615005493\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.765625 \n",
      "\n",
      "EPOCH: 190\n",
      "Total loss = 5.493261337280273 \n",
      "\tLosses: adv_generator = 3.4393420219421387, mnist_classifier = 0.6940973997116089, discriminator = 0.6657246351242065\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.703125 \n",
      "\n",
      "EPOCH: 191\n",
      "Total loss = 5.567734241485596 \n",
      "\tLosses: adv_generator = 3.7579126358032227, mnist_classifier = 0.6940961480140686, discriminator = 0.42162954807281494\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 192\n",
      "Total loss = 5.718479633331299 \n",
      "\tLosses: adv_generator = 3.8369908332824707, mnist_classifier = 0.6940950751304626, discriminator = 0.49329859018325806\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 193\n",
      "Total loss = 5.382452964782715 \n",
      "\tLosses: adv_generator = 3.3660058975219727, mnist_classifier = 0.6940939426422119, discriminator = 0.6282592415809631\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 194\n",
      "Total loss = 5.303538799285889 \n",
      "\tLosses: adv_generator = 3.386404275894165, mnist_classifier = 0.694092869758606, discriminator = 0.5289487838745117\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 195\n",
      "Total loss = 5.623379707336426 \n",
      "\tLosses: adv_generator = 3.840806245803833, mnist_classifier = 0.6940918564796448, discriminator = 0.39438942074775696\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 196\n",
      "Total loss = 5.600442886352539 \n",
      "\tLosses: adv_generator = 3.6685965061187744, mnist_classifier = 0.6940907835960388, discriminator = 0.5436651110649109\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 197\n",
      "Total loss = 5.3473005294799805 \n",
      "\tLosses: adv_generator = 3.3416929244995117, mnist_classifier = 0.6940896511077881, discriminator = 0.6174283623695374\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.765625 \n",
      "\n",
      "EPOCH: 198\n",
      "Total loss = 5.555108070373535 \n",
      "\tLosses: adv_generator = 3.651370048522949, mnist_classifier = 0.6940885186195374, discriminator = 0.5155608654022217\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 199\n",
      "Total loss = 5.505709648132324 \n",
      "\tLosses: adv_generator = 3.595716953277588, mnist_classifier = 0.6940874457359314, discriminator = 0.5218177437782288\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 200\n",
      "Total loss = 5.502141952514648 \n",
      "\tLosses: adv_generator = 3.6093196868896484, mnist_classifier = 0.6940863132476807, discriminator = 0.504649817943573\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 201\n",
      "Total loss = 5.549513816833496 \n",
      "\tLosses: adv_generator = 3.4384396076202393, mnist_classifier = 0.6940851807594299, discriminator = 0.7229036092758179\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 202\n",
      "Total loss = 5.558803081512451 \n",
      "\tLosses: adv_generator = 3.657093048095703, mnist_classifier = 0.694084107875824, discriminator = 0.5135415196418762\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 203\n",
      "Total loss = 5.466761589050293 \n",
      "\tLosses: adv_generator = 3.7690012454986572, mnist_classifier = 0.6940830945968628, discriminator = 0.30959439277648926\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9140625 \n",
      "\n",
      "EPOCH: 204\n",
      "Total loss = 5.507417678833008 \n",
      "\tLosses: adv_generator = 3.465491771697998, mnist_classifier = 0.6940819025039673, discriminator = 0.653761625289917\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 205\n",
      "Total loss = 5.2978129386901855 \n",
      "\tLosses: adv_generator = 3.4159281253814697, mnist_classifier = 0.6940808892250061, discriminator = 0.4937230348587036\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 206\n",
      "Total loss = 5.525475978851318 \n",
      "\tLosses: adv_generator = 3.759408473968506, mnist_classifier = 0.6940798163414001, discriminator = 0.3779076039791107\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 207\n",
      "Total loss = 5.353206634521484 \n",
      "\tLosses: adv_generator = 3.386472463607788, mnist_classifier = 0.694078803062439, discriminator = 0.5785765647888184\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.765625 \n",
      "\n",
      "EPOCH: 208\n",
      "Total loss = 5.461765766143799 \n",
      "\tLosses: adv_generator = 3.4158616065979004, mnist_classifier = 0.6940776109695435, discriminator = 0.6577486991882324\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7421875 \n",
      "\n",
      "EPOCH: 209\n",
      "Total loss = 5.318917751312256 \n",
      "\tLosses: adv_generator = 3.487236499786377, mnist_classifier = 0.6940765976905823, discriminator = 0.4435283839702606\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 210\n",
      "Total loss = 5.378149509429932 \n",
      "\tLosses: adv_generator = 3.5616869926452637, mnist_classifier = 0.6940755248069763, discriminator = 0.42831140756607056\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 211\n",
      "Total loss = 5.456189155578613 \n",
      "\tLosses: adv_generator = 3.6115798950195312, mnist_classifier = 0.6940743923187256, discriminator = 0.45646047592163086\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 212\n",
      "Total loss = 5.153438091278076 \n",
      "\tLosses: adv_generator = 3.082750082015991, mnist_classifier = 0.6940732598304749, discriminator = 0.6825412511825562\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.71875 \n",
      "\n",
      "EPOCH: 213\n",
      "Total loss = 5.491971492767334 \n",
      "\tLosses: adv_generator = 3.592240810394287, mnist_classifier = 0.6940722465515137, discriminator = 0.5115863084793091\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 214\n",
      "Total loss = 5.291025638580322 \n",
      "\tLosses: adv_generator = 3.4609336853027344, mnist_classifier = 0.6940712332725525, discriminator = 0.44194933772087097\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 215\n",
      "Total loss = 5.349390983581543 \n",
      "\tLosses: adv_generator = 3.3219876289367676, mnist_classifier = 0.6940701007843018, discriminator = 0.6392632722854614\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.75 \n",
      "\n",
      "EPOCH: 216\n",
      "Total loss = 5.335036754608154 \n",
      "\tLosses: adv_generator = 3.556626081466675, mnist_classifier = 0.694068968296051, discriminator = 0.39027267694473267\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 217\n",
      "Total loss = 5.597227573394775 \n",
      "\tLosses: adv_generator = 3.595689535140991, mnist_classifier = 0.6940679550170898, discriminator = 0.6134017109870911\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 218\n",
      "Total loss = 5.250475883483887 \n",
      "\tLosses: adv_generator = 3.50167179107666, mnist_classifier = 0.6940669417381287, discriminator = 0.3606700301170349\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 219\n",
      "Total loss = 5.492413520812988 \n",
      "\tLosses: adv_generator = 3.42767333984375, mnist_classifier = 0.6940658092498779, discriminator = 0.6766085624694824\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 220\n",
      "Total loss = 5.468372821807861 \n",
      "\tLosses: adv_generator = 3.469139814376831, mnist_classifier = 0.6940646767616272, discriminator = 0.6111034154891968\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 221\n",
      "Total loss = 5.295703411102295 \n",
      "\tLosses: adv_generator = 3.385127067565918, mnist_classifier = 0.6940637230873108, discriminator = 0.5224488973617554\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 222\n",
      "Total loss = 5.319647312164307 \n",
      "\tLosses: adv_generator = 3.462610960006714, mnist_classifier = 0.6940626502037048, discriminator = 0.46891120076179504\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 223\n",
      "Total loss = 5.442440032958984 \n",
      "\tLosses: adv_generator = 3.57502818107605, mnist_classifier = 0.6940616369247437, discriminator = 0.47928881645202637\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 224\n",
      "Total loss = 5.276732444763184 \n",
      "\tLosses: adv_generator = 3.4482455253601074, mnist_classifier = 0.6940604448318481, discriminator = 0.4403655529022217\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 225\n",
      "Total loss = 5.506958484649658 \n",
      "\tLosses: adv_generator = 3.554058313369751, mnist_classifier = 0.694059431552887, discriminator = 0.5647813677787781\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 226\n",
      "Total loss = 5.295319080352783 \n",
      "\tLosses: adv_generator = 3.526336669921875, mnist_classifier = 0.6940584182739258, discriminator = 0.3808656930923462\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 227\n",
      "Total loss = 5.138883590698242 \n",
      "\tLosses: adv_generator = 3.2111656665802, mnist_classifier = 0.6940574049949646, discriminator = 0.5396032929420471\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 228\n",
      "Total loss = 5.280156135559082 \n",
      "\tLosses: adv_generator = 3.394951105117798, mnist_classifier = 0.6940563917160034, discriminator = 0.49709200859069824\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 229\n",
      "Total loss = 5.430934906005859 \n",
      "\tLosses: adv_generator = 3.5745065212249756, mnist_classifier = 0.6940551996231079, discriminator = 0.46831780672073364\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 230\n",
      "Total loss = 5.302183151245117 \n",
      "\tLosses: adv_generator = 3.456958770751953, mnist_classifier = 0.6940541863441467, discriminator = 0.45711633563041687\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 231\n",
      "Total loss = 5.5237298011779785 \n",
      "\tLosses: adv_generator = 3.3632304668426514, mnist_classifier = 0.6940531134605408, discriminator = 0.7723933458328247\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.625 \n",
      "\n",
      "EPOCH: 232\n",
      "Total loss = 5.326179027557373 \n",
      "\tLosses: adv_generator = 3.534137725830078, mnist_classifier = 0.6940521597862244, discriminator = 0.40393680334091187\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 233\n",
      "Total loss = 5.402541160583496 \n",
      "\tLosses: adv_generator = 3.601029634475708, mnist_classifier = 0.6940510272979736, discriminator = 0.4134089946746826\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 234\n",
      "Total loss = 5.476639270782471 \n",
      "\tLosses: adv_generator = 3.592684030532837, mnist_classifier = 0.6940499544143677, discriminator = 0.4958552420139313\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 235\n",
      "Total loss = 5.292807579040527 \n",
      "\tLosses: adv_generator = 3.3210508823394775, mnist_classifier = 0.6940489411354065, discriminator = 0.5836589336395264\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 236\n",
      "Total loss = 5.429358959197998 \n",
      "\tLosses: adv_generator = 3.631030559539795, mnist_classifier = 0.6940478682518005, discriminator = 0.4102323353290558\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 237\n",
      "Total loss = 5.270895004272461 \n",
      "\tLosses: adv_generator = 3.4345178604125977, mnist_classifier = 0.6940469145774841, discriminator = 0.448283314704895\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 238\n",
      "Total loss = 5.2311248779296875 \n",
      "\tLosses: adv_generator = 3.3234658241271973, mnist_classifier = 0.694045901298523, discriminator = 0.5195672512054443\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 239\n",
      "Total loss = 5.505012512207031 \n",
      "\tLosses: adv_generator = 3.572283983230591, mnist_classifier = 0.6940447092056274, discriminator = 0.544638991355896\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 240\n",
      "Total loss = 5.45350456237793 \n",
      "\tLosses: adv_generator = 3.6573972702026367, mnist_classifier = 0.6940436959266663, discriminator = 0.40802001953125\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 241\n",
      "Total loss = 5.454921245574951 \n",
      "\tLosses: adv_generator = 3.5529725551605225, mnist_classifier = 0.6940427422523499, discriminator = 0.5138630867004395\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 242\n",
      "Total loss = 5.244878768920898 \n",
      "\tLosses: adv_generator = 3.306364059448242, mnist_classifier = 0.6940417289733887, discriminator = 0.5504311919212341\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 243\n",
      "Total loss = 5.540626049041748 \n",
      "\tLosses: adv_generator = 3.6646766662597656, mnist_classifier = 0.6940407156944275, discriminator = 0.48786771297454834\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 244\n",
      "Total loss = 5.6419806480407715 \n",
      "\tLosses: adv_generator = 3.7490792274475098, mnist_classifier = 0.6940397024154663, discriminator = 0.5048221349716187\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 245\n",
      "Total loss = 5.208983898162842 \n",
      "\tLosses: adv_generator = 3.4131031036376953, mnist_classifier = 0.6940386295318604, discriminator = 0.407803475856781\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 246\n",
      "Total loss = 5.476423263549805 \n",
      "\tLosses: adv_generator = 3.4901390075683594, mnist_classifier = 0.6940374970436096, discriminator = 0.5982093811035156\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7578125 \n",
      "\n",
      "EPOCH: 247\n",
      "Total loss = 5.566813945770264 \n",
      "\tLosses: adv_generator = 3.8875794410705566, mnist_classifier = 0.6940365433692932, discriminator = 0.2911613881587982\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 248\n",
      "Total loss = 5.322225570678711 \n",
      "\tLosses: adv_generator = 3.5282175540924072, mnist_classifier = 0.6940354704856873, discriminator = 0.4059370458126068\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 249\n",
      "Total loss = 5.382068157196045 \n",
      "\tLosses: adv_generator = 3.1656038761138916, mnist_classifier = 0.6940345168113708, discriminator = 0.8283955454826355\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.671875 \n",
      "\n",
      "EPOCH: 250\n",
      "Total loss = 5.843867778778076 \n",
      "\tLosses: adv_generator = 4.02958869934082, mnist_classifier = 0.6940335631370544, discriminator = 0.4262116551399231\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 251\n",
      "Total loss = 5.471513748168945 \n",
      "\tLosses: adv_generator = 3.8017027378082275, mnist_classifier = 0.6940324306488037, discriminator = 0.28174591064453125\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 252\n",
      "Total loss = 5.584490776062012 \n",
      "\tLosses: adv_generator = 3.6523799896240234, mnist_classifier = 0.6940313577651978, discriminator = 0.5440481901168823\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 253\n",
      "Total loss = 5.849529266357422 \n",
      "\tLosses: adv_generator = 3.990083694458008, mnist_classifier = 0.6940303444862366, discriminator = 0.4713852107524872\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 254\n",
      "Total loss = 5.039923667907715 \n",
      "\tLosses: adv_generator = 3.3138153553009033, mnist_classifier = 0.6940293908119202, discriminator = 0.33804917335510254\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 255\n",
      "Total loss = 5.822875499725342 \n",
      "\tLosses: adv_generator = 3.8777737617492676, mnist_classifier = 0.6940284371376038, discriminator = 0.5570449233055115\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 256\n",
      "Total loss = 5.560590744018555 \n",
      "\tLosses: adv_generator = 3.749586582183838, mnist_classifier = 0.6940274238586426, discriminator = 0.4229494631290436\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 257\n",
      "Total loss = 5.405016899108887 \n",
      "\tLosses: adv_generator = 3.464644432067871, mnist_classifier = 0.6940264701843262, discriminator = 0.5523194074630737\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 258\n",
      "Total loss = 5.899904727935791 \n",
      "\tLosses: adv_generator = 3.900238513946533, mnist_classifier = 0.694025456905365, discriminator = 0.6116153001785278\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7578125 \n",
      "\n",
      "EPOCH: 259\n",
      "Total loss = 5.578167915344238 \n",
      "\tLosses: adv_generator = 3.981739044189453, mnist_classifier = 0.6940245032310486, discriminator = 0.2083796262741089\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.96875 \n",
      "\n",
      "EPOCH: 260\n",
      "Total loss = 5.634907245635986 \n",
      "\tLosses: adv_generator = 3.6854965686798096, mnist_classifier = 0.6940234899520874, discriminator = 0.5613638162612915\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 261\n",
      "Total loss = 6.009917736053467 \n",
      "\tLosses: adv_generator = 3.7198455333709717, mnist_classifier = 0.6940224170684814, discriminator = 0.9020276665687561\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6015625 \n",
      "\n",
      "EPOCH: 262\n",
      "Total loss = 5.530458450317383 \n",
      "\tLosses: adv_generator = 3.903712034225464, mnist_classifier = 0.6940213441848755, discriminator = 0.23870372772216797\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9453125 \n",
      "\n",
      "EPOCH: 263\n",
      "Total loss = 5.606481552124023 \n",
      "\tLosses: adv_generator = 3.930696487426758, mnist_classifier = 0.6940203309059143, discriminator = 0.2877447009086609\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.96875 \n",
      "\n",
      "EPOCH: 264\n",
      "Total loss = 5.670316219329834 \n",
      "\tLosses: adv_generator = 3.4460411071777344, mnist_classifier = 0.6940193772315979, discriminator = 0.8362365961074829\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.625 \n",
      "\n",
      "EPOCH: 265\n",
      "Total loss = 5.579341888427734 \n",
      "\tLosses: adv_generator = 3.6543495655059814, mnist_classifier = 0.6940183639526367, discriminator = 0.536955714225769\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 266\n",
      "Total loss = 5.506130218505859 \n",
      "\tLosses: adv_generator = 3.861281633377075, mnist_classifier = 0.6940173506736755, discriminator = 0.25681421160697937\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9609375 \n",
      "\n",
      "EPOCH: 267\n",
      "Total loss = 5.395050525665283 \n",
      "\tLosses: adv_generator = 3.6135387420654297, mnist_classifier = 0.6940163969993591, discriminator = 0.39347898960113525\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 268\n",
      "Total loss = 5.486852169036865 \n",
      "\tLosses: adv_generator = 3.2611265182495117, mnist_classifier = 0.6940154433250427, discriminator = 0.8376946449279785\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.625 \n",
      "\n",
      "EPOCH: 269\n",
      "Total loss = 5.409338474273682 \n",
      "\tLosses: adv_generator = 3.4892492294311523, mnist_classifier = 0.6940144896507263, discriminator = 0.5320602655410767\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 270\n",
      "Total loss = 5.55477237701416 \n",
      "\tLosses: adv_generator = 3.732973575592041, mnist_classifier = 0.6940133571624756, discriminator = 0.43377232551574707\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8203125 \n",
      "\n",
      "EPOCH: 271\n",
      "Total loss = 5.307041168212891 \n",
      "\tLosses: adv_generator = 3.463228702545166, mnist_classifier = 0.6940124034881592, discriminator = 0.45578789710998535\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 272\n",
      "Total loss = 5.318655014038086 \n",
      "\tLosses: adv_generator = 3.4744138717651367, mnist_classifier = 0.6940113306045532, discriminator = 0.45621854066848755\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 273\n",
      "Total loss = 5.508263111114502 \n",
      "\tLosses: adv_generator = 3.459775686264038, mnist_classifier = 0.6940103769302368, discriminator = 0.6604664921760559\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7421875 \n",
      "\n",
      "EPOCH: 274\n",
      "Total loss = 5.399811744689941 \n",
      "\tLosses: adv_generator = 3.569244861602783, mnist_classifier = 0.6940094232559204, discriminator = 0.4425475597381592\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 275\n",
      "Total loss = 5.255936145782471 \n",
      "\tLosses: adv_generator = 3.5662341117858887, mnist_classifier = 0.6940084099769592, discriminator = 0.3016854524612427\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 276\n",
      "Total loss = 5.3320465087890625 \n",
      "\tLosses: adv_generator = 3.386413097381592, mnist_classifier = 0.6940074563026428, discriminator = 0.5576185584068298\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 277\n",
      "Total loss = 5.340200901031494 \n",
      "\tLosses: adv_generator = 3.260498046875, mnist_classifier = 0.6940065026283264, discriminator = 0.6916899681091309\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.734375 \n",
      "\n",
      "EPOCH: 278\n",
      "Total loss = 5.222600936889648 \n",
      "\tLosses: adv_generator = 3.567293643951416, mnist_classifier = 0.6940054893493652, discriminator = 0.2672964334487915\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9375 \n",
      "\n",
      "EPOCH: 279\n",
      "Total loss = 5.3431901931762695 \n",
      "\tLosses: adv_generator = 3.6197848320007324, mnist_classifier = 0.6940045356750488, discriminator = 0.33539628982543945\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 280\n",
      "Total loss = 5.170028209686279 \n",
      "\tLosses: adv_generator = 3.038741111755371, mnist_classifier = 0.6940035223960876, discriminator = 0.7432798147201538\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.671875 \n",
      "\n",
      "EPOCH: 281\n",
      "Total loss = 5.282608509063721 \n",
      "\tLosses: adv_generator = 3.2931911945343018, mnist_classifier = 0.6940025687217712, discriminator = 0.6014121770858765\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 282\n",
      "Total loss = 5.316183567047119 \n",
      "\tLosses: adv_generator = 3.601039409637451, mnist_classifier = 0.6940016150474548, discriminator = 0.3271406292915344\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 283\n",
      "Total loss = 5.201623439788818 \n",
      "\tLosses: adv_generator = 3.464550018310547, mnist_classifier = 0.6940006613731384, discriminator = 0.34907180070877075\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 284\n",
      "Total loss = 5.378612995147705 \n",
      "\tLosses: adv_generator = 3.274238109588623, mnist_classifier = 0.6939996480941772, discriminator = 0.7163758277893066\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.703125 \n",
      "\n",
      "EPOCH: 285\n",
      "Total loss = 5.282803058624268 \n",
      "\tLosses: adv_generator = 3.5616514682769775, mnist_classifier = 0.6939986944198608, discriminator = 0.3331541121006012\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 286\n",
      "Total loss = 5.348330497741699 \n",
      "\tLosses: adv_generator = 3.5619192123413086, mnist_classifier = 0.6939977407455444, discriminator = 0.3984154462814331\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 287\n",
      "Total loss = 5.366616249084473 \n",
      "\tLosses: adv_generator = 3.42014741897583, mnist_classifier = 0.6939966678619385, discriminator = 0.5584753751754761\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 288\n",
      "Total loss = 5.171453475952148 \n",
      "\tLosses: adv_generator = 3.0610837936401367, mnist_classifier = 0.6939958333969116, discriminator = 0.7223778367042542\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6953125 \n",
      "\n",
      "EPOCH: 289\n",
      "Total loss = 5.333583831787109 \n",
      "\tLosses: adv_generator = 3.5000295639038086, mnist_classifier = 0.6939947605133057, discriminator = 0.4455649256706238\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 290\n",
      "Total loss = 5.271381855010986 \n",
      "\tLosses: adv_generator = 3.5852136611938477, mnist_classifier = 0.6939938068389893, discriminator = 0.2981806993484497\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9375 \n",
      "\n",
      "EPOCH: 291\n",
      "Total loss = 5.210506439208984 \n",
      "\tLosses: adv_generator = 3.3519973754882812, mnist_classifier = 0.6939928531646729, discriminator = 0.47052329778671265\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 292\n",
      "Total loss = 5.268257141113281 \n",
      "\tLosses: adv_generator = 3.213301181793213, mnist_classifier = 0.6939918994903564, discriminator = 0.6669721007347107\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.734375 \n",
      "\n",
      "EPOCH: 293\n",
      "Total loss = 5.347141265869141 \n",
      "\tLosses: adv_generator = 3.496185541152954, mnist_classifier = 0.69399094581604, discriminator = 0.46297353506088257\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 294\n",
      "Total loss = 5.199222087860107 \n",
      "\tLosses: adv_generator = 3.4758903980255127, mnist_classifier = 0.6939898729324341, discriminator = 0.3353520929813385\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 295\n",
      "Total loss = 5.338383674621582 \n",
      "\tLosses: adv_generator = 3.332061767578125, mnist_classifier = 0.6939889192581177, discriminator = 0.6183444261550903\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 296\n",
      "Total loss = 5.135006904602051 \n",
      "\tLosses: adv_generator = 3.238931655883789, mnist_classifier = 0.6939879655838013, discriminator = 0.5080997347831726\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 297\n",
      "Total loss = 5.334555149078369 \n",
      "\tLosses: adv_generator = 3.4718573093414307, mnist_classifier = 0.6939870119094849, discriminator = 0.4747239053249359\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 298\n",
      "Total loss = 5.177159309387207 \n",
      "\tLosses: adv_generator = 3.409071445465088, mnist_classifier = 0.6939860582351685, discriminator = 0.38011544942855835\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 299\n",
      "Total loss = 5.320063591003418 \n",
      "\tLosses: adv_generator = 3.4404799938201904, mnist_classifier = 0.693985104560852, discriminator = 0.491613507270813\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 300\n",
      "Total loss = 5.136293888092041 \n",
      "\tLosses: adv_generator = 3.1799659729003906, mnist_classifier = 0.6939840912818909, discriminator = 0.5683599710464478\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 301\n",
      "Total loss = 5.183452606201172 \n",
      "\tLosses: adv_generator = 3.4121055603027344, mnist_classifier = 0.6939831972122192, discriminator = 0.38338083028793335\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 302\n",
      "Total loss = 5.181441307067871 \n",
      "\tLosses: adv_generator = 3.3596925735473633, mnist_classifier = 0.6939822435379028, discriminator = 0.433784544467926\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 303\n",
      "Total loss = 5.366033554077148 \n",
      "\tLosses: adv_generator = 3.3468217849731445, mnist_classifier = 0.6939812898635864, discriminator = 0.6312495470046997\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 304\n",
      "Total loss = 5.267171382904053 \n",
      "\tLosses: adv_generator = 3.4477570056915283, mnist_classifier = 0.69398033618927, discriminator = 0.4314537048339844\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 305\n",
      "Total loss = 5.370341777801514 \n",
      "\tLosses: adv_generator = 3.5053040981292725, mnist_classifier = 0.6939793825149536, discriminator = 0.4770788252353668\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 306\n",
      "Total loss = 5.315488338470459 \n",
      "\tLosses: adv_generator = 3.5345237255096436, mnist_classifier = 0.6939784288406372, discriminator = 0.39300763607025146\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 307\n",
      "Total loss = 5.230012893676758 \n",
      "\tLosses: adv_generator = 3.353428840637207, mnist_classifier = 0.6939774751663208, discriminator = 0.4886291027069092\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 308\n",
      "Total loss = 5.244542598724365 \n",
      "\tLosses: adv_generator = 3.2370758056640625, mnist_classifier = 0.693976640701294, discriminator = 0.6195136308670044\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 309\n",
      "Total loss = 5.226927757263184 \n",
      "\tLosses: adv_generator = 3.4070916175842285, mnist_classifier = 0.693975567817688, discriminator = 0.4318850040435791\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 310\n",
      "Total loss = 5.293096542358398 \n",
      "\tLosses: adv_generator = 3.4734976291656494, mnist_classifier = 0.6939747333526611, discriminator = 0.43164926767349243\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 311\n",
      "Total loss = 5.220839977264404 \n",
      "\tLosses: adv_generator = 3.3909292221069336, mnist_classifier = 0.6939737796783447, discriminator = 0.4419630765914917\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 312\n",
      "Total loss = 5.313124656677246 \n",
      "\tLosses: adv_generator = 3.2698984146118164, mnist_classifier = 0.6939729452133179, discriminator = 0.6552802920341492\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 313\n",
      "Total loss = 5.100942611694336 \n",
      "\tLosses: adv_generator = 3.3803343772888184, mnist_classifier = 0.6939718723297119, discriminator = 0.33266451954841614\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.90625 \n",
      "\n",
      "EPOCH: 314\n",
      "Total loss = 5.279097080230713 \n",
      "\tLosses: adv_generator = 3.6153221130371094, mnist_classifier = 0.6939710378646851, discriminator = 0.27583247423171997\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9609375 \n",
      "\n",
      "EPOCH: 315\n",
      "Total loss = 5.166904449462891 \n",
      "\tLosses: adv_generator = 3.204888343811035, mnist_classifier = 0.6939700841903687, discriminator = 0.5740755796432495\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7578125 \n",
      "\n",
      "EPOCH: 316\n",
      "Total loss = 5.083613395690918 \n",
      "\tLosses: adv_generator = 3.233422040939331, mnist_classifier = 0.693969190120697, discriminator = 0.4622528851032257\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 317\n",
      "Total loss = 5.164541721343994 \n",
      "\tLosses: adv_generator = 3.3573203086853027, mnist_classifier = 0.6939682364463806, discriminator = 0.4192846417427063\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 318\n",
      "Total loss = 5.318673133850098 \n",
      "\tLosses: adv_generator = 3.404264211654663, mnist_classifier = 0.6939672827720642, discriminator = 0.5264743566513062\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 319\n",
      "Total loss = 5.202178001403809 \n",
      "\tLosses: adv_generator = 3.43727970123291, mnist_classifier = 0.6939663290977478, discriminator = 0.37696534395217896\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 320\n",
      "Total loss = 5.273099899291992 \n",
      "\tLosses: adv_generator = 3.384826421737671, mnist_classifier = 0.6939653754234314, discriminator = 0.5003427267074585\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 321\n",
      "Total loss = 5.411468029022217 \n",
      "\tLosses: adv_generator = 3.3126425743103027, mnist_classifier = 0.693964421749115, discriminator = 0.7108964920043945\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7578125 \n",
      "\n",
      "EPOCH: 322\n",
      "Total loss = 5.372627258300781 \n",
      "\tLosses: adv_generator = 3.701551914215088, mnist_classifier = 0.6939635276794434, discriminator = 0.28314846754074097\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.953125 \n",
      "\n",
      "EPOCH: 323\n",
      "Total loss = 5.243067264556885 \n",
      "\tLosses: adv_generator = 3.433866024017334, mnist_classifier = 0.693962574005127, discriminator = 0.4212760925292969\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 324\n",
      "Total loss = 5.384675979614258 \n",
      "\tLosses: adv_generator = 3.3395638465881348, mnist_classifier = 0.6939616799354553, discriminator = 0.6571887135505676\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7578125 \n",
      "\n",
      "EPOCH: 325\n",
      "Total loss = 5.3113250732421875 \n",
      "\tLosses: adv_generator = 3.43135666847229, mnist_classifier = 0.6939607262611389, discriminator = 0.4920470118522644\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 326\n",
      "Total loss = 5.23638916015625 \n",
      "\tLosses: adv_generator = 3.5822649002075195, mnist_classifier = 0.6939597725868225, discriminator = 0.2662048935890198\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9375 \n",
      "\n",
      "EPOCH: 327\n",
      "Total loss = 5.284894943237305 \n",
      "\tLosses: adv_generator = 3.2768802642822266, mnist_classifier = 0.6939588189125061, discriminator = 0.6200971603393555\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7578125 \n",
      "\n",
      "EPOCH: 328\n",
      "Total loss = 5.4981889724731445 \n",
      "\tLosses: adv_generator = 3.7103257179260254, mnist_classifier = 0.6939579248428345, discriminator = 0.39994725584983826\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 329\n",
      "Total loss = 5.105739116668701 \n",
      "\tLosses: adv_generator = 3.409186840057373, mnist_classifier = 0.6939570903778076, discriminator = 0.30863815546035767\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 330\n",
      "Total loss = 5.330354690551758 \n",
      "\tLosses: adv_generator = 3.5775539875030518, mnist_classifier = 0.6939562559127808, discriminator = 0.36488842964172363\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 331\n",
      "Total loss = 5.499294757843018 \n",
      "\tLosses: adv_generator = 3.5821824073791504, mnist_classifier = 0.6939553618431091, discriminator = 0.5292016267776489\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8125 \n",
      "\n",
      "EPOCH: 332\n",
      "Total loss = 5.118564605712891 \n",
      "\tLosses: adv_generator = 3.1638846397399902, mnist_classifier = 0.6939544081687927, discriminator = 0.5667712688446045\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8046875 \n",
      "\n",
      "EPOCH: 333\n",
      "Total loss = 5.484407424926758 \n",
      "\tLosses: adv_generator = 3.6469852924346924, mnist_classifier = 0.6939534544944763, discriminator = 0.4495152235031128\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 334\n",
      "Total loss = 5.325583457946777 \n",
      "\tLosses: adv_generator = 3.6018285751342773, mnist_classifier = 0.6939525604248047, discriminator = 0.3358495533466339\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 335\n",
      "Total loss = 5.204204082489014 \n",
      "\tLosses: adv_generator = 3.4805986881256104, mnist_classifier = 0.6939516663551331, discriminator = 0.3357020616531372\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 336\n",
      "Total loss = 5.497989177703857 \n",
      "\tLosses: adv_generator = 3.4071297645568848, mnist_classifier = 0.6939507126808167, discriminator = 0.7029579877853394\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6640625 \n",
      "\n",
      "EPOCH: 337\n",
      "Total loss = 5.529536724090576 \n",
      "\tLosses: adv_generator = 3.815800666809082, mnist_classifier = 0.693949818611145, discriminator = 0.32583683729171753\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9140625 \n",
      "\n",
      "EPOCH: 338\n",
      "Total loss = 5.0813517570495605 \n",
      "\tLosses: adv_generator = 3.3626513481140137, mnist_classifier = 0.6939489841461182, discriminator = 0.330802321434021\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 339\n",
      "Total loss = 5.7760162353515625 \n",
      "\tLosses: adv_generator = 3.556262969970703, mnist_classifier = 0.6939479112625122, discriminator = 0.8318579196929932\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.6015625 \n",
      "\n",
      "EPOCH: 340\n",
      "Total loss = 5.336147308349609 \n",
      "\tLosses: adv_generator = 3.581784248352051, mnist_classifier = 0.6939470767974854, discriminator = 0.36646878719329834\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9375 \n",
      "\n",
      "EPOCH: 341\n",
      "Total loss = 5.394811630249023 \n",
      "\tLosses: adv_generator = 3.6688191890716553, mnist_classifier = 0.6939463019371033, discriminator = 0.3381000757217407\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 342\n",
      "Total loss = 5.6036152839660645 \n",
      "\tLosses: adv_generator = 3.7886617183685303, mnist_classifier = 0.6939453482627869, discriminator = 0.4270631670951843\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 343\n",
      "Total loss = 5.139281749725342 \n",
      "\tLosses: adv_generator = 3.2105870246887207, mnist_classifier = 0.6939443945884705, discriminator = 0.5408058762550354\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7734375 \n",
      "\n",
      "EPOCH: 344\n",
      "Total loss = 5.480891704559326 \n",
      "\tLosses: adv_generator = 3.626220226287842, mnist_classifier = 0.6939435005187988, discriminator = 0.46678465604782104\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 345\n",
      "Total loss = 5.144023895263672 \n",
      "\tLosses: adv_generator = 3.3306326866149902, mnist_classifier = 0.6939426064491272, discriminator = 0.4255062937736511\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 346\n",
      "Total loss = 5.370518684387207 \n",
      "\tLosses: adv_generator = 3.3650741577148438, mnist_classifier = 0.6939416527748108, discriminator = 0.6175612807273865\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 347\n",
      "Total loss = 5.226642608642578 \n",
      "\tLosses: adv_generator = 3.429298162460327, mnist_classifier = 0.6939407587051392, discriminator = 0.40946298837661743\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 348\n",
      "Total loss = 5.108027935028076 \n",
      "\tLosses: adv_generator = 3.3754115104675293, mnist_classifier = 0.6939399242401123, discriminator = 0.3447365462779999\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.921875 \n",
      "\n",
      "EPOCH: 349\n",
      "Total loss = 5.21255350112915 \n",
      "\tLosses: adv_generator = 3.248971700668335, mnist_classifier = 0.6939390897750854, discriminator = 0.5757036209106445\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 350\n",
      "Total loss = 5.4697265625 \n",
      "\tLosses: adv_generator = 3.4962823390960693, mnist_classifier = 0.6939381957054138, discriminator = 0.5855680108070374\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.75 \n",
      "\n",
      "EPOCH: 351\n",
      "Total loss = 5.286380767822266 \n",
      "\tLosses: adv_generator = 3.6512904167175293, mnist_classifier = 0.6939372420310974, discriminator = 0.24721553921699524\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9453125 \n",
      "\n",
      "EPOCH: 352\n",
      "Total loss = 5.206336498260498 \n",
      "\tLosses: adv_generator = 3.4590988159179688, mnist_classifier = 0.6939363479614258, discriminator = 0.3593650460243225\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 353\n",
      "Total loss = 5.422031402587891 \n",
      "\tLosses: adv_generator = 3.1340880393981934, mnist_classifier = 0.6939354538917542, discriminator = 0.9000726938247681\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.5859375 \n",
      "\n",
      "EPOCH: 354\n",
      "Total loss = 5.11732292175293 \n",
      "\tLosses: adv_generator = 3.4262256622314453, mnist_classifier = 0.6939345598220825, discriminator = 0.3032281994819641\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 355\n",
      "Total loss = 5.625040531158447 \n",
      "\tLosses: adv_generator = 3.949751853942871, mnist_classifier = 0.6939336061477661, discriminator = 0.2874218821525574\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9140625 \n",
      "\n",
      "EPOCH: 356\n",
      "Total loss = 5.1854119300842285 \n",
      "\tLosses: adv_generator = 3.362187385559082, mnist_classifier = 0.6939328908920288, discriminator = 0.4353586435317993\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 357\n",
      "Total loss = 5.3684587478637695 \n",
      "\tLosses: adv_generator = 3.2103822231292725, mnist_classifier = 0.6939319968223572, discriminator = 0.7702126502990723\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 358\n",
      "Total loss = 5.116235733032227 \n",
      "\tLosses: adv_generator = 3.1964635848999023, mnist_classifier = 0.6939310431480408, discriminator = 0.5319101810455322\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7890625 \n",
      "\n",
      "EPOCH: 359\n",
      "Total loss = 5.303066730499268 \n",
      "\tLosses: adv_generator = 3.615276336669922, mnist_classifier = 0.6939301490783691, discriminator = 0.29993006587028503\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9296875 \n",
      "\n",
      "EPOCH: 360\n",
      "Total loss = 5.304593563079834 \n",
      "\tLosses: adv_generator = 3.478745937347412, mnist_classifier = 0.6939292550086975, discriminator = 0.4379890263080597\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8515625 \n",
      "\n",
      "EPOCH: 361\n",
      "Total loss = 5.2747650146484375 \n",
      "\tLosses: adv_generator = 3.24130916595459, mnist_classifier = 0.6939283013343811, discriminator = 0.6455991268157959\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.7265625 \n",
      "\n",
      "EPOCH: 362\n",
      "Total loss = 5.142423629760742 \n",
      "\tLosses: adv_generator = 3.2148845195770264, mnist_classifier = 0.6939274072647095, discriminator = 0.539684534072876\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 363\n",
      "Total loss = 5.336782455444336 \n",
      "\tLosses: adv_generator = 3.553765058517456, mnist_classifier = 0.6939266920089722, discriminator = 0.3951641321182251\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 364\n",
      "Total loss = 5.140794277191162 \n",
      "\tLosses: adv_generator = 3.360654354095459, mnist_classifier = 0.6939257979393005, discriminator = 0.39228832721710205\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8828125 \n",
      "\n",
      "EPOCH: 365\n",
      "Total loss = 5.245962619781494 \n",
      "\tLosses: adv_generator = 3.2010152339935303, mnist_classifier = 0.6939248442649841, discriminator = 0.6570979952812195\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 366\n",
      "Total loss = 5.109097957611084 \n",
      "\tLosses: adv_generator = 3.2547528743743896, mnist_classifier = 0.6939240097999573, discriminator = 0.4664970338344574\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 367\n",
      "Total loss = 5.188482284545898 \n",
      "\tLosses: adv_generator = 3.409794569015503, mnist_classifier = 0.6939231157302856, discriminator = 0.3908414840698242\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 368\n",
      "Total loss = 5.098589897155762 \n",
      "\tLosses: adv_generator = 3.2522029876708984, mnist_classifier = 0.6939222812652588, discriminator = 0.45854246616363525\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 369\n",
      "Total loss = 5.233356475830078 \n",
      "\tLosses: adv_generator = 3.3749589920043945, mnist_classifier = 0.6939215064048767, discriminator = 0.470554381608963\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 370\n",
      "Total loss = 5.155257225036621 \n",
      "\tLosses: adv_generator = 3.2458362579345703, mnist_classifier = 0.6939205527305603, discriminator = 0.5215795040130615\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.796875 \n",
      "\n",
      "EPOCH: 371\n",
      "Total loss = 5.178208827972412 \n",
      "\tLosses: adv_generator = 3.3918871879577637, mnist_classifier = 0.6939196586608887, discriminator = 0.39848217368125916\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8984375 \n",
      "\n",
      "EPOCH: 372\n",
      "Total loss = 5.054507255554199 \n",
      "\tLosses: adv_generator = 3.237485647201538, mnist_classifier = 0.693918764591217, discriminator = 0.4291837513446808\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.875 \n",
      "\n",
      "EPOCH: 373\n",
      "Total loss = 5.235066890716553 \n",
      "\tLosses: adv_generator = 3.261321544647217, mnist_classifier = 0.6939178705215454, discriminator = 0.5859094858169556\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.765625 \n",
      "\n",
      "EPOCH: 374\n",
      "Total loss = 5.035563945770264 \n",
      "\tLosses: adv_generator = 3.1931254863739014, mnist_classifier = 0.6939171552658081, discriminator = 0.4546041488647461\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n",
      "EPOCH: 375\n",
      "Total loss = 5.107413291931152 \n",
      "\tLosses: adv_generator = 3.2426958084106445, mnist_classifier = 0.6939162611961365, discriminator = 0.47688502073287964\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.84375 \n",
      "\n",
      "EPOCH: 376\n",
      "Total loss = 5.00046443939209 \n",
      "\tLosses: adv_generator = 3.1777496337890625, mnist_classifier = 0.6939153671264648, discriminator = 0.4348839521408081\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8671875 \n",
      "\n",
      "EPOCH: 377\n",
      "Total loss = 5.02911376953125 \n",
      "\tLosses: adv_generator = 3.1585586071014404, mnist_classifier = 0.6939144730567932, discriminator = 0.4827260971069336\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.8359375 \n",
      "\n",
      "EPOCH: 378\n",
      "Total loss = 5.089925289154053 \n",
      "\tLosses: adv_generator = 3.2611875534057617, mnist_classifier = 0.6939135789871216, discriminator = 0.4409106373786926\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.859375 \n",
      "\n",
      "EPOCH: 379\n",
      "Total loss = 5.23570442199707 \n",
      "\tLosses: adv_generator = 3.4416725635528564, mnist_classifier = 0.6939128637313843, discriminator = 0.4062063694000244\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.890625 \n",
      "\n",
      "EPOCH: 380\n",
      "Total loss = 5.0996012687683105 \n",
      "\tLosses: adv_generator = 3.3413589000701904, mnist_classifier = 0.6939119696617126, discriminator = 0.37041860818862915\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.9140625 \n",
      "\n",
      "EPOCH: 381\n",
      "Total loss = 5.179531097412109 \n",
      "\tLosses: adv_generator = 3.145643711090088, mnist_classifier = 0.693911075592041, discriminator = 0.6460652947425842\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.78125 \n",
      "\n",
      "EPOCH: 382\n",
      "Total loss = 5.17710018157959 \n",
      "\tLosses: adv_generator = 3.2712507247924805, mnist_classifier = 0.6939101815223694, discriminator = 0.5180291533470154\n",
      "\tAccuracy: adv_generator = 0.0, mnist_classifier = 0.0, discriminator = 0.828125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128 \n",
    "EPOCHS = 1000\n",
    "\n",
    "y_real = np.ones((BATCH_SIZE, 1))\n",
    "y_fake = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "# Targeted Attack\n",
    "target_label = 0\n",
    "target_prediction = np.zeros(10)\n",
    "target_prediction[target_label] = 1\n",
    "target_prediction = np.array([target_prediction]*BATCH_SIZE)\n",
    "\n",
    "hinge_limit = np.array([[c]]*BATCH_SIZE)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    if time.time() - start_time > 60*60*8:\n",
    "        break   # time limit of 8 hours\n",
    "\n",
    "    x_real = np.array(random.choices(train_X, k=BATCH_SIZE))\n",
    "    \n",
    "    perturbations = adv_generator.predict(x_real, verbose=0)\n",
    "    x_fake = x_real + perturbations\n",
    "\n",
    "    y = {\n",
    "        \"mnist_classifier\": target_prediction,\n",
    "        \"discriminator\": y_real,\n",
    "        \"adv_generator\": perturbations\n",
    "    }\n",
    "    loss = advGAN_model.train_on_batch(x=x_real, y=y)\n",
    "\n",
    "    # We want our discriminator to learn about fakes after\n",
    "    discriminator.train_on_batch(x=x_real, y=y_real)\n",
    "    discriminator.train_on_batch(x=x_fake, y=y_fake)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"EPOCH: {epoch}\")\n",
    "        print(f\"Total loss = {loss[0]} \\n\\tLosses: adv_generator = {loss[1]}, mnist_classifier = {loss[2]}, discriminator = {loss[3]}\\n\\tAccuracy: adv_generator = {loss[4]}, mnist_classifier = {loss[5]}, discriminator = {loss[6]} \\n\")\n",
    "        # print(f\"Total loss = {loss[0]} \\n\\tLosses: mnist_classifier = {loss[1]}, discriminator = {loss[2]}\\n\\tAccuracy: mnist_classifier = {loss[3]}, discriminator = {loss[4]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_generator.save_weights(\"mnist_adv_generator2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save_weights(\"mnist_adv_discriminator2.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
      "p_fake = 0, p_real = 0\n",
      "p_fake = 9, p_real = 9\n",
      "p_fake = 8, p_real = 8\n",
      "p_fake = 6, p_real = 6\n",
      "p_fake = 0, p_real = 1\n",
      "p_fake = 0, p_real = 0\n",
      "p_fake = 8, p_real = 8\n",
      "p_fake = 1, p_real = 1\n",
      "p_fake = 1, p_real = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_real = np.array(random.choices(test_X, k=9))\n",
    "\n",
    "perturbations = adv_generator.predict(x_real)\n",
    "x_fake = np.add(x_real, perturbations)\n",
    "x_fake = np.clip(x_fake, 0, 1) # Values in image is [0,1]\n",
    "x_fake_labels = model.predict(x_fake, steps=1)\n",
    "x_real_labels = model.predict(x_real)\n",
    "\n",
    "for i in range(9):\n",
    "    fig = plt.subplot(3, 3, i+1)\n",
    "    fig.imshow(x_fake[i], cmap=plt.get_cmap('gray'))\n",
    "    print(f'p_fake = {np.argmax(x_fake_labels[i])}, p_real = {np.argmax(x_real_labels[i])}')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Attacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m         FGM_test_X \u001b[39m=\u001b[39m FGM\u001b[39m.\u001b[39mgenerate(FGM_test_X, target_prediction)\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m FGM_test_X\n\u001b[1;32m---> 25\u001b[0m FGM_test_X \u001b[39m=\u001b[39m fast_gradient_attack(test_X, clf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "import art\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "def fast_gradient_attack(x_test, clf):\n",
    "\n",
    "    FGM = FastGradientMethod(clf, eps=0.01, targeted=True, batch_size=32)\n",
    "\n",
    "    # Targeted Attack\n",
    "    target_label = 0\n",
    "    target_prediction = np.zeros(10)\n",
    "    target_prediction[target_label] = 1\n",
    "    target_prediction = np.zeros([len(x_test), 1])\n",
    "\n",
    "    STEPS = 100\n",
    "\n",
    "    FGM_test_X = FGM.generate(x_test, target_prediction)\n",
    "    for step in range(STEPS):\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Iter: {step}\")\n",
    "        FGM_test_X = FGM.generate(FGM_test_X, target_prediction)\n",
    "\n",
    "    return FGM_test_X\n",
    "\n",
    "FGM_test_X = fast_gradient_attack(test_X, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.24991024169922, 0.098]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(FGM_test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake = 0, p_real = 7\n",
      "p_fake = 0, p_real = 2\n",
      "p_fake = 0, p_real = 1\n",
      "p_fake = 0, p_real = 0\n",
      "p_fake = 0, p_real = 4\n",
      "p_fake = 0, p_real = 1\n",
      "p_fake = 0, p_real = 4\n",
      "p_fake = 0, p_real = 9\n",
      "p_fake = 0, p_real = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_real = test_X[:9]\n",
    "\n",
    "x_fake = FGM_test_X[:9]\n",
    "x_fake_labels = model.predict(x_fake)\n",
    "x_real_labels = model.predict(x_real)\n",
    "\n",
    "for i in range(9):\n",
    "    fig = plt.subplot(3, 3, i+1)\n",
    "    fig.imshow(x_fake[i], cmap=plt.get_cmap('gray'))\n",
    "    print(f'p_fake = {np.argmax(x_fake_labels[i])}, p_real = {np.argmax(x_real_labels[i])}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "def PGD_attack(x_test, clf):\n",
    "    PGD = ProjectedGradientDescent(clf, eps=0.01, targeted=True, batch_size=32)\n",
    "\n",
    "\n",
    "    \n",
    "    target_label = 0\n",
    "    target_prediction = np.zeros(10)\n",
    "    target_prediction[target_label] = 1\n",
    "    target_prediction = np.zeros([len(x_test), 1])\n",
    "\n",
    "    STEPS = 100\n",
    "\n",
    "    PGD_test_X = PGD.generate(x_test, target_prediction)\n",
    "    for step in range(STEPS):\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Iter: {step}\")\n",
    "        PGD_test_X = PGD.generate(FGM_test_X, target_prediction)\n",
    "\n",
    "    return PGD_test_X\n",
    "\n",
    "PGD_test_X = fast_gradient_attack(test_X, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aae92b6a0ba24f8871a612dac6f7421aefe2ea759412b548419fc8838c5b682a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
